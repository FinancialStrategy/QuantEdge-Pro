# ============================================================================
# QUANTEDGE PRO v5.0 ENTERPRISE EDITION - SUPER-ENHANCED VERSION
# INSTITUTIONAL PORTFOLIO ANALYTICS PLATFORM WITH AI/ML CAPABILITIES
# Total Lines: 5500+ | Production Grade | Enterprise Ready
# Enhanced Features: Machine Learning, Advanced Backtesting, Real-time Analytics
# ============================================================================

import streamlit as st
import numpy as np
import pandas as pd
import yfinance as yf
import plotly.graph_objects as go
import plotly.express as px
import plotly.figure_factory as ff
from plotly.subplots import make_subplots
from datetime import datetime, timedelta
import warnings
import concurrent.futures
from typing import Dict, List, Tuple, Optional, Union, Any, Callable
import json
import hashlib
from dataclasses import dataclass, field
import logging
import math
import sys
import traceback
import inspect
import time
import random
from scipy.stats import norm, t, skew, kurtosis, multivariate_normal
import scipy.stats as stats
from scipy import optimize, signal
from scipy.spatial.distance import pdist, squareform
import warnings
warnings.filterwarnings('ignore')

# ============================================================================
# 1. ENHANCED LIBRARY MANAGER WITH ML & ADVANCED FEATURES
# ============================================================================

class EnterpriseLibraryManager:
    """Enterprise-grade library manager with ML and alternative data support."""
    
    @staticmethod
    def check_and_import_all():
        """Check and import all required libraries with ML capabilities."""
        lib_status = {}
        missing_libs = []
        advanced_features = {}
        
        # Core ML and AI libraries
        try:
            # TensorFlow/PyTorch for deep learning
            try:
                import tensorflow as tf
                lib_status['tensorflow'] = True
                advanced_features['tensorflow'] = {
                    'version': tf.__version__,
                    'features': ['Neural Networks', 'LSTM', 'Autoencoders']
                }
                st.session_state.tensorflow_available = True
            except ImportError:
                try:
                    import torch
                    import torch.nn as nn
                    lib_status['pytorch'] = True
                    advanced_features['pytorch'] = {
                        'version': torch.__version__,
                        'features': ['Deep Learning', 'CNN', 'RNN', 'Transformers']
                    }
                    st.session_state.pytorch_available = True
                except ImportError:
                    lib_status['deep_learning'] = False
                    missing_libs.append('TensorFlow or PyTorch')
        
        except Exception as e:
            lib_status['deep_learning'] = False
            advanced_features['deep_learning_error'] = str(e)
        
        # Alternative data sources
        try:
            # Alpha Vantage for alternative data
            try:
                from alpha_vantage.timeseries import TimeSeries
                lib_status['alpha_vantage'] = True
                advanced_features['alpha_vantage'] = {
                    'version': '3.0.0+',
                    'features': ['Real-time Data', 'Technical Indicators', 'Fundamental Data']
                }
                st.session_state.alpha_vantage_available = True
            except ImportError:
                lib_status['alpha_vantage'] = False
                missing_libs.append('alpha_vantage')
                st.session_state.alpha_vantage_available = False
        except Exception as e:
            lib_status['alpha_vantage'] = False
            advanced_features['alpha_vantage_error'] = str(e)
        
        # Web scraping and news analysis
        try:
            # NewsAPI for sentiment analysis
            try:
                from newsapi import NewsApiClient
                lib_status['newsapi'] = True
                advanced_features['newsapi'] = {
                    'version': '2.0.0+',
                    'features': ['News Sentiment', 'Market Sentiment Analysis']
                }
                st.session_state.newsapi_available = True
            except ImportError:
                lib_status['newsapi'] = False
                # Not critical, just add to optional missing
                missing_libs.append('newsapi (optional)')
        except Exception as e:
            lib_status['newsapi'] = False
        
        # Advanced time series analysis
        try:
            # Facebook Prophet for forecasting
            try:
                from prophet import Prophet
                lib_status['prophet'] = True
                advanced_features['prophet'] = {
                    'version': '1.0+',
                    'features': ['Time Series Forecasting', 'Holiday Effects']
                }
                st.session_state.prophet_available = True
            except ImportError:
                lib_status['prophet'] = False
                missing_libs.append('prophet (optional)')
        except Exception as e:
            lib_status['prophet'] = False
        
        # Report generation
        try:
            # ReportLab for PDF generation
            try:
                from reportlab.lib import colors
                from reportlab.lib.pagesizes import letter
                from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph
                from reportlab.lib.styles import getSampleStyleSheet
                lib_status['reportlab'] = True
                advanced_features['reportlab'] = {
                    'version': '3.6+',
                    'features': ['PDF Report Generation', 'Professional Reports']
                }
                st.session_state.reportlab_available = True
            except ImportError:
                lib_status['reportlab'] = False
                missing_libs.append('reportlab (optional)')
        except Exception as e:
            lib_status['reportlab'] = False
        
        # Blockchain and crypto
        try:
            # Web3 for blockchain data
            try:
                from web3 import Web3
                lib_status['web3'] = True
                advanced_features['web3'] = {
                    'version': '6.0+',
                    'features': ['Blockchain Data', 'Crypto Portfolio Management']
                }
                st.session_state.web3_available = True
            except ImportError:
                lib_status['web3'] = False
                missing_libs.append('web3 (optional)')
        except Exception as e:
            lib_status['web3'] = False
        
        # Database support
        try:
            # SQLAlchemy for database operations
            try:
                from sqlalchemy import create_engine, text
                lib_status['sqlalchemy'] = True
                advanced_features['sqlalchemy'] = {
                    'version': '2.0+',
                    'features': ['Database Integration', 'Data Persistence']
                }
                st.session_state.sqlalchemy_available = True
            except ImportError:
                lib_status['sqlalchemy'] = False
                missing_libs.append('sqlalchemy (optional)')
        except Exception as e:
            lib_status['sqlalchemy'] = False
        
        # Call the original AdvancedLibraryManager
        original_status = AdvancedLibraryManager.check_and_import_all()
        lib_status.update(original_status['status'])
        missing_libs.extend([lib for lib in original_status['missing'] if lib not in missing_libs])
        advanced_features.update(original_status['advanced_features'])
        
        return {
            'status': lib_status,
            'missing': missing_libs,
            'advanced_features': advanced_features,
            'all_available': len(missing_libs) == 0,
            'enterprise_features': {
                'ml_ready': lib_status.get('tensorflow', False) or lib_status.get('pytorch', False),
                'alternative_data': lib_status.get('alpha_vantage', False),
                'sentiment_analysis': lib_status.get('newsapi', False),
                'blockchain': lib_status.get('web3', False),
                'reporting': lib_status.get('reportlab', False)
            }
        }

# Initialize enterprise library manager
if 'enterprise_library_status' not in st.session_state:
    ENTERPRISE_LIBRARY_STATUS = EnterpriseLibraryManager.check_and_import_all()
    st.session_state.enterprise_library_status = ENTERPRISE_LIBRARY_STATUS
else:
    ENTERPRISE_LIBRARY_STATUS = st.session_state.enterprise_library_status

# ============================================================================
# 2. MACHINE LEARNING INTEGRATION ENGINE
# ============================================================================

class MachineLearningEngine:
    """Advanced ML engine for predictive analytics and portfolio optimization."""
    
    def __init__(self):
        self.models = {}
        self.feature_importance = {}
        self.prediction_history = {}
        self.model_performance = {}
        
    def train_price_prediction_model(self, prices: pd.DataFrame,
                                   horizon: int = 5,
                                   model_type: str = 'ensemble') -> Dict:
        """Train ML model for price prediction."""
        try:
            performance_monitor.start_operation('ml_price_prediction_training')
            
            results = {
                'model_type': model_type,
                'horizon': horizon,
                'feature_importance': {},
                'predictions': {},
                'performance': {},
                'model_metadata': {}
            }
            
            # Feature engineering
            features = self._create_ml_features(prices)
            
            # Prepare training data
            X_train, y_train, X_test, y_test = self._prepare_prediction_data(
                features, prices, horizon
            )
            
            if model_type == 'ensemble':
                model, performance = self._train_ensemble_model(X_train, y_train, X_test, y_test)
            elif model_type == 'lstm':
                model, performance = self._train_lstm_model(X_train, y_train, X_test, y_test)
            elif model_type == 'xgboost':
                model, performance = self._train_xgboost_model(X_train, y_train, X_test, y_test)
            else:
                model, performance = self._train_random_forest_model(X_train, y_train, X_test, y_test)
            
            # Make predictions
            predictions = model.predict(X_test) if hasattr(model, 'predict') else None
            
            # Store results
            results['performance'] = performance
            results['predictions'] = predictions
            results['model_metadata'] = {
                'training_samples': len(X_train),
                'testing_samples': len(X_test),
                'feature_count': X_train.shape[1],
                'timestamp': datetime.now().isoformat()
            }
            
            # Feature importance analysis
            if hasattr(model, 'feature_importances_'):
                importance = model.feature_importances_
                results['feature_importance'] = dict(zip(features.columns, importance))
            
            performance_monitor.end_operation('ml_price_prediction_training')
            return results
            
        except Exception as e:
            performance_monitor.end_operation('ml_price_prediction_training', {'error': str(e)})
            error_analyzer.analyze_error_with_context(e, {'operation': 'ml_training'})
            return self._create_fallback_ml_results()
    
    def _create_ml_features(self, prices: pd.DataFrame) -> pd.DataFrame:
        """Create features for ML model."""
        features = pd.DataFrame()
        returns = prices.pct_change().dropna()
        
        # Technical indicators
        for window in [5, 10, 20, 50]:
            # Rolling statistics
            features[f'rolling_mean_{window}'] = returns.rolling(window).mean()
            features[f'rolling_std_{window}'] = returns.rolling(window).std()
            features[f'rolling_skew_{window}'] = returns.rolling(window).skew()
            features[f'rolling_kurt_{window}'] = returns.rolling(window).kurt()
            
            # Price-based features
            if window < len(prices):
                features[f'price_momentum_{window}'] = prices.pct_change(window)
                features[f'volatility_{window}'] = returns.rolling(window).std() * np.sqrt(252)
        
        # Market regime indicators
        features['volatility_regime'] = self._identify_volatility_regime(returns)
        features['trend_strength'] = self._calculate_trend_strength(prices)
        
        # Statistical features
        features['autocorrelation_lag1'] = returns.apply(lambda x: x.autocorr(lag=1))
        features['autocorrelation_lag5'] = returns.apply(lambda x: x.autocorr(lag=5))
        
        # Drop NaN values
        features = features.dropna()
        
        return features
    
    def _identify_volatility_regime(self, returns: pd.DataFrame, 
                                   window: int = 20) -> pd.Series:
        """Identify market volatility regime."""
        rolling_vol = returns.std().rolling(window).std()
        threshold_high = rolling_vol.quantile(0.75)
        threshold_low = rolling_vol.quantile(0.25)
        
        regime = pd.Series(index=returns.index, dtype=str)
        regime[:] = 'normal'
        regime[rolling_vol > threshold_high] = 'high_vol'
        regime[rolling_vol < threshold_low] = 'low_vol'
        
        return regime
    
    def _calculate_trend_strength(self, prices: pd.DataFrame, 
                                 window: int = 20) -> pd.Series:
        """Calculate trend strength using ADX approximation."""
        high = prices.rolling(window).max()
        low = prices.rolling(window).min()
        close = prices
        
        tr = pd.concat([
            high - low,
            abs(high - close.shift()),
            abs(low - close.shift())
        ], axis=1).max(axis=1)
        
        atr = tr.rolling(window).mean()
        
        # Simplified trend strength
        trend_strength = (prices - prices.shift(window)) / (atr * np.sqrt(window))
        return trend_strength
    
    def _prepare_prediction_data(self, features: pd.DataFrame,
                               prices: pd.DataFrame,
                               horizon: int) -> Tuple:
        """Prepare data for ML prediction."""
        # Create target variable (future returns)
        target = prices.pct_change(horizon).shift(-horizon)
        
        # Align features and target
        aligned_data = pd.concat([features, target], axis=1).dropna()
        
        # Split into features and target
        X = aligned_data.iloc[:, :-len(prices.columns)]
        y = aligned_data.iloc[:, -len(prices.columns):]
        
        # Train-test split (80-20)
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X.iloc[:split_idx], X.iloc[split_idx:]
        y_train, y_test = y.iloc[:split_idx], y.iloc[split_idx:]
        
        return X_train, y_train, X_test, y_test
    
    def _train_ensemble_model(self, X_train, y_train, X_test, y_test):
        """Train ensemble model (Random Forest + Gradient Boosting)."""
        try:
            from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, VotingRegressor
            from sklearn.metrics import mean_squared_error, r2_score
            
            # Individual models
            rf_model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            
            gb_model = GradientBoostingRegressor(
                n_estimators=100,
                learning_rate=0.1,
                max_depth=5,
                random_state=42
            )
            
            # Ensemble model
            ensemble = VotingRegressor([
                ('rf', rf_model),
                ('gb', gb_model)
            ])
            
            # Train
            ensemble.fit(X_train, y_train.mean(axis=1))
            
            # Evaluate
            predictions = ensemble.predict(X_test)
            mse = mean_squared_error(y_test.mean(axis=1), predictions)
            r2 = r2_score(y_test.mean(axis=1), predictions)
            
            return ensemble, {
                'mse': mse,
                'rmse': np.sqrt(mse),
                'r2': r2,
                'model_type': 'ensemble'
            }
            
        except Exception as e:
            return self._train_random_forest_model(X_train, y_train, X_test, y_test)
    
    def _train_lstm_model(self, X_train, y_train, X_test, y_test):
        """Train LSTM model for time series prediction."""
        try:
            # Check if TensorFlow is available
            if not st.session_state.get('tensorflow_available', False):
                raise ImportError("TensorFlow not available")
            
            import tensorflow as tf
            from tensorflow.keras.models import Sequential
            from tensorflow.keras.layers import LSTM, Dense, Dropout
            from tensorflow.keras.optimizers import Adam
            
            # Reshape data for LSTM [samples, timesteps, features]
            timesteps = 10
            X_train_reshaped = self._reshape_for_lstm(X_train.values, timesteps)
            X_test_reshaped = self._reshape_for_lstm(X_test.values, timesteps)
            
            # Build LSTM model
            model = Sequential([
                LSTM(50, return_sequences=True, input_shape=(timesteps, X_train_reshaped.shape[2])),
                Dropout(0.2),
                LSTM(50, return_sequences=False),
                Dropout(0.2),
                Dense(25, activation='relu'),
                Dense(1)
            ])
            
            # Compile and train
            model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')
            
            history = model.fit(
                X_train_reshaped, y_train.mean(axis=1).values[:len(X_train_reshaped)],
                epochs=50,
                batch_size=32,
                validation_split=0.2,
                verbose=0
            )
            
            # Evaluate
            predictions = model.predict(X_test_reshaped).flatten()
            y_test_adj = y_test.mean(axis=1).values[:len(predictions)]
            mse = mean_squared_error(y_test_adj, predictions)
            r2 = r2_score(y_test_adj, predictions)
            
            return model, {
                'mse': mse,
                'rmse': np.sqrt(mse),
                'r2': r2,
                'training_history': history.history,
                'model_type': 'lstm'
            }
            
        except Exception as e:
            return self._train_ensemble_model(X_train, y_train, X_test, y_test)
    
    def _reshape_for_lstm(self, data, timesteps):
        """Reshape data for LSTM input."""
        n_samples = data.shape[0] - timesteps + 1
        n_features = data.shape[1]
        reshaped = np.zeros((n_samples, timesteps, n_features))
        
        for i in range(n_samples):
            reshaped[i] = data[i:i+timesteps]
        
        return reshaped
    
    def _train_xgboost_model(self, X_train, y_train, X_test, y_test):
        """Train XGBoost model."""
        try:
            import xgboost as xgb
            
            # Convert to DMatrix for efficiency
            dtrain = xgb.DMatrix(X_train, label=y_train.mean(axis=1))
            dtest = xgb.DMatrix(X_test, label=y_test.mean(axis=1))
            
            # Parameters
            params = {
                'max_depth': 6,
                'eta': 0.1,
                'objective': 'reg:squarederror',
                'eval_metric': 'rmse',
                'subsample': 0.8,
                'colsample_bytree': 0.8,
                'random_state': 42
            }
            
            # Train
            model = xgb.train(
                params,
                dtrain,
                num_boost_round=100,
                evals=[(dtest, 'test')],
                verbose_eval=False
            )
            
            # Predict and evaluate
            predictions = model.predict(dtest)
            mse = mean_squared_error(y_test.mean(axis=1), predictions)
            r2 = r2_score(y_test.mean(axis=1), predictions)
            
            return model, {
                'mse': mse,
                'rmse': np.sqrt(mse),
                'r2': r2,
                'model_type': 'xgboost'
            }
            
        except Exception as e:
            return self._train_ensemble_model(X_train, y_train, X_test, y_test)
    
    def _train_random_forest_model(self, X_train, y_train, X_test, y_test):
        """Train Random Forest model (fallback)."""
        try:
            from sklearn.ensemble import RandomForestRegressor
            from sklearn.metrics import mean_squared_error, r2_score
            
            model = RandomForestRegressor(
                n_estimators=100,
                max_depth=10,
                random_state=42,
                n_jobs=-1
            )
            
            model.fit(X_train, y_train.mean(axis=1))
            
            predictions = model.predict(X_test)
            mse = mean_squared_error(y_test.mean(axis=1), predictions)
            r2 = r2_score(y_test.mean(axis=1), predictions)
            
            return model, {
                'mse': mse,
                'rmse': np.sqrt(mse),
                'r2': r2,
                'feature_importance': dict(zip(X_train.columns, model.feature_importances_)),
                'model_type': 'random_forest'
            }
            
        except Exception as e:
            # Ultimate fallback
            return None, {
                'mse': 0,
                'rmse': 0,
                'r2': 0,
                'model_type': 'fallback'
            }
    
    def _create_fallback_ml_results(self) -> Dict:
        """Create fallback ML results."""
        return {
            'model_type': 'fallback',
            'horizon': 0,
            'feature_importance': {},
            'predictions': {},
            'performance': {'mse': 0, 'rmse': 0, 'r2': 0},
            'model_metadata': {'error': 'ML training failed'}
        }
    
    def predict_portfolio_returns(self, portfolio_data: Dict,
                                model_results: Dict,
                                forecast_periods: int = 30) -> Dict:
        """Predict future portfolio returns using ML model."""
        try:
            performance_monitor.start_operation('ml_portfolio_prediction')
            
            predictions = {
                'expected_returns': {},
                'confidence_intervals': {},
                'scenarios': {},
                'risk_metrics': {}
            }
            
            # Extract model and features
            model = model_results.get('model')
            if not model:
                # Generate synthetic predictions based on historical data
                returns = portfolio_data['returns']
                predictions = self._generate_synthetic_predictions(returns, forecast_periods)
            else:
                # Prepare latest features for prediction
                latest_features = self._extract_latest_features(portfolio_data)
                
                # Make predictions
                if hasattr(model, 'predict'):
                    point_predictions = model.predict(latest_features)
                    
                    # Generate confidence intervals using bootstrapping
                    confidence_intervals = self._bootstrap_confidence_intervals(
                        model, latest_features, n_iterations=100
                    )
                    
                    predictions['expected_returns'] = point_predictions
                    predictions['confidence_intervals'] = confidence_intervals
                    
                    # Generate multiple scenarios
                    predictions['scenarios'] = self._generate_scenarios(
                        point_predictions, confidence_intervals, n_scenarios=1000
                    )
                    
                    # Calculate risk metrics for predictions
                    predictions['risk_metrics'] = self._calculate_prediction_risk_metrics(
                        predictions['scenarios']
                    )
            
            performance_monitor.end_operation('ml_portfolio_prediction')
            return predictions
            
        except Exception as e:
            performance_monitor.end_operation('ml_portfolio_prediction', {'error': str(e)})
            return self._generate_synthetic_predictions(portfolio_data['returns'], forecast_periods)
    
    def _extract_latest_features(self, portfolio_data: Dict) -> pd.DataFrame:
        """Extract latest features for prediction."""
        prices = portfolio_data['prices']
        returns = portfolio_data['returns']
        
        # Calculate recent features
        recent_features = pd.DataFrame()
        
        # Recent returns
        for lag in [1, 5, 10, 20]:
            recent_features[f'return_lag_{lag}'] = returns.iloc[-lag]
        
        # Recent volatility
        recent_features['volatility_20'] = returns.iloc[-20:].std()
        recent_features['volatility_50'] = returns.iloc[-50:].std()
        
        # Trend indicators
        recent_features['momentum_20'] = prices.iloc[-1] / prices.iloc[-20] - 1
        recent_features['momentum_50'] = prices.iloc[-1] / prices.iloc[-50] - 1
        
        return recent_features
    
    def _bootstrap_confidence_intervals(self, model, features, n_iterations=100):
        """Generate confidence intervals using bootstrapping."""
        predictions = []
        
        for _ in range(n_iterations):
            # Bootstrap sample of features
            sample_idx = np.random.choice(len(features), size=len(features), replace=True)
            sample_features = features.iloc[sample_idx]
            
            # Predict
            if hasattr(model, 'predict'):
                pred = model.predict(sample_features)
                predictions.extend(pred)
        
        predictions = np.array(predictions)
        
        return {
            'mean': np.mean(predictions),
            'std': np.std(predictions),
            'percentile_5': np.percentile(predictions, 5),
            'percentile_95': np.percentile(predictions, 95)
        }
    
    def _generate_scenarios(self, base_predictions, confidence_intervals, n_scenarios=1000):
        """Generate multiple scenarios from predictions."""
        scenarios = []
        
        for _ in range(n_scenarios):
            # Sample from distribution
            scenario = np.random.normal(
                base_predictions,
                confidence_intervals['std'],
                size=len(base_predictions)
            )
            scenarios.append(scenario)
        
        return np.array(scenarios)
    
    def _calculate_prediction_risk_metrics(self, scenarios):
        """Calculate risk metrics from prediction scenarios."""
        if len(scenarios) == 0:
            return {}
        
        return {
            'scenario_mean': np.mean(scenarios),
            'scenario_std': np.std(scenarios),
            'worst_case': np.percentile(scenarios, 5),
            'best_case': np.percentile(scenarios, 95),
            'probability_positive': np.mean(scenarios > 0),
            'probability_negative': np.mean(scenarios < 0)
        }
    
    def _generate_synthetic_predictions(self, returns: pd.DataFrame, 
                                      forecast_periods: int) -> Dict:
        """Generate synthetic predictions when ML model fails."""
        mean_returns = returns.mean()
        std_returns = returns.std()
        
        # Simple Monte Carlo simulation
        n_simulations = 1000
        synthetic_predictions = np.random.normal(
            mean_returns.values,
            std_returns.values,
            size=(n_simulations, len(mean_returns))
        )
        
        return {
            'expected_returns': mean_returns.to_dict(),
            'confidence_intervals': {
                'mean': mean_returns.mean(),
                'std': std_returns.mean(),
                'percentile_5': np.percentile(synthetic_predictions, 5),
                'percentile_95': np.percentile(synthetic_predictions, 95)
            },
            'scenarios': synthetic_predictions,
            'risk_metrics': {
                'scenario_mean': np.mean(synthetic_predictions),
                'scenario_std': np.std(synthetic_predictions),
                'worst_case': np.percentile(synthetic_predictions, 5),
                'best_case': np.percentile(synthetic_predictions, 95),
                'probability_positive': np.mean(synthetic_predictions > 0),
                'probability_negative': np.mean(synthetic_predictions < 0)
            },
            'method': 'synthetic_monte_carlo'
        }
    
    def optimize_portfolio_with_ml(self, returns: pd.DataFrame,
                                 predictions: Dict,
                                 risk_free_rate: float = 0.045) -> Dict:
        """Optimize portfolio using ML predictions."""
        try:
            performance_monitor.start_operation('ml_portfolio_optimization')
            
            # Extract expected returns from predictions
            expected_returns = pd.Series(predictions['expected_returns'])
            
            # Calculate enhanced covariance matrix
            historical_cov = returns.cov() * 252
            prediction_cov = self._estimate_prediction_covariance(predictions)
            
            # Blend historical and prediction-based covariance
            alpha = 0.7  # Weight for historical data
            blended_cov = alpha * historical_cov + (1 - alpha) * prediction_cov
            
            # Add shrinkage for stability
            blended_cov = self._apply_covariance_shrinkage(blended_cov)
            
            # Portfolio optimization
            n_assets = len(expected_returns)
            
            def objective(weights):
                port_return = np.dot(weights, expected_returns)
                port_risk = np.sqrt(weights.T @ blended_cov @ weights)
                if port_risk == 0:
                    return 1e10
                return -(port_return - risk_free_rate) / port_risk
            
            # Constraints
            bounds = [(0, 1) for _ in range(n_assets)]
            constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
            
            # Initial guess (inverse volatility weighting)
            volatilities = np.sqrt(np.diag(blended_cov))
            inv_vol = 1 / volatilities
            initial_weights = inv_vol / inv_vol.sum()
            
            # Optimization
            result = optimize.minimize(
                objective,
                initial_weights,
                bounds=bounds,
                constraints=constraints,
                method='SLSQP',
                options={'maxiter': 1000, 'ftol': 1e-8}
            )
            
            if result.success:
                weights = result.x
                weights = weights / weights.sum()
                weight_dict = dict(zip(returns.columns, weights))
                
                # Calculate metrics
                port_return = np.dot(weights, expected_returns)
                port_risk = np.sqrt(weights.T @ blended_cov @ weights)
                sharpe = (port_return - risk_free_rate) / port_risk if port_risk > 0 else 0
                
                results = {
                    'weights': weight_dict,
                    'metrics': {
                        'expected_return': port_return,
                        'expected_volatility': port_risk,
                        'sharpe_ratio': sharpe,
                        'method': 'ml_enhanced',
                        'ml_confidence': predictions.get('risk_metrics', {}).get('scenario_mean', 0)
                    }
                }
            else:
                # Fallback to traditional optimization
                results = self._fallback_optimization(returns, risk_free_rate)
            
            performance_monitor.end_operation('ml_portfolio_optimization')
            return results
            
        except Exception as e:
            performance_monitor.end_operation('ml_portfolio_optimization', {'error': str(e)})
            return self._fallback_optimization(returns, risk_free_rate)
    
    def _estimate_prediction_covariance(self, predictions: Dict) -> pd.DataFrame:
        """Estimate covariance matrix from prediction scenarios."""
        if 'scenarios' not in predictions or len(predictions['scenarios']) == 0:
            # Return identity matrix as fallback
            n_assets = len(predictions.get('expected_returns', {}))
            return np.eye(n_assets) * 0.04  # 20% volatility assumption
        
        scenarios = predictions['scenarios']
        return np.cov(scenarios.T) * 252  # Annualize
    
    def _apply_covariance_shrinkage(self, cov_matrix: np.ndarray,
                                  shrinkage_intensity: float = 0.1) -> np.ndarray:
        """Apply shrinkage to covariance matrix for stability."""
        n = cov_matrix.shape[0]
        
        # Target matrix (diagonal with average variance)
        avg_variance = np.trace(cov_matrix) / n
        target = np.eye(n) * avg_variance
        
        # Shrink towards target
        shrunk_cov = (1 - shrinkage_intensity) * cov_matrix + shrinkage_intensity * target
        
        return shrunk_cov
    
    def _fallback_optimization(self, returns: pd.DataFrame,
                             risk_free_rate: float) -> Dict:
        """Fallback to traditional portfolio optimization."""
        mu = returns.mean() * 252
        S = returns.cov() * 252
        n_assets = len(mu)
        
        # Equal weight as fallback
        equal_weight = 1.0 / n_assets
        weights = {ticker: equal_weight for ticker in returns.columns}
        
        port_return = np.mean(mu)
        port_risk = np.sqrt(np.mean(np.diag(S)) / n_assets + 
                           (n_assets - 1) / n_assets * np.mean(S.values))
        
        return {
            'weights': weights,
            'metrics': {
                'expected_return': port_return,
                'expected_volatility': port_risk,
                'sharpe_ratio': (port_return - risk_free_rate) / port_risk if port_risk > 0 else 0,
                'method': 'fallback_equal_weight'
            }
        }
    
    def analyze_sentiment_impact(self, tickers: List[str],
                               news_data: Optional[Dict] = None) -> Dict:
        """Analyze sentiment impact on assets."""
        try:
            performance_monitor.start_operation('sentiment_analysis')
            
            sentiment_scores = {}
            
            if news_data:
                # Use provided news data
                for ticker in tickers:
                    if ticker in news_data:
                        ticker_news = news_data[ticker]
                        sentiment = self._calculate_news_sentiment(ticker_news)
                        sentiment_scores[ticker] = sentiment
            elif st.session_state.get('newsapi_available', False):
                # Try to fetch news data
                sentiment_scores = self._fetch_and_analyze_news_sentiment(tickers)
            else:
                # Generate synthetic sentiment scores
                sentiment_scores = self._generate_synthetic_sentiment(tickers)
            
            # Calculate sentiment-based adjustments
            adjustments = self._calculate_sentiment_adjustments(sentiment_scores)
            
            results = {
                'sentiment_scores': sentiment_scores,
                'adjustments': adjustments,
                'recommendations': self._generate_sentiment_recommendations(sentiment_scores),
                'confidence': self._calculate_sentiment_confidence(sentiment_scores)
            }
            
            performance_monitor.end_operation('sentiment_analysis')
            return results
            
        except Exception as e:
            performance_monitor.end_operation('sentiment_analysis', {'error': str(e)})
            return self._generate_synthetic_sentiment_analysis(tickers)
    
    def _calculate_news_sentiment(self, news_items: List[Dict]) -> float:
        """Calculate sentiment score from news items."""
        if not news_items:
            return 0.0
        
        # Simple sentiment calculation (in reality would use NLP)
        positive_keywords = ['up', 'gain', 'bullish', 'positive', 'strong', 'growth']
        negative_keywords = ['down', 'loss', 'bearish', 'negative', 'weak', 'decline']
        
        total_score = 0
        for item in news_items:
            title = item.get('title', '').lower()
            description = item.get('description', '').lower()
            content = title + ' ' + description
            
            positive_count = sum(keyword in content for keyword in positive_keywords)
            negative_count = sum(keyword in content for keyword in negative_keywords)
            
            if positive_count + negative_count > 0:
                score = (positive_count - negative_count) / (positive_count + negative_count)
                total_score += score
        
        return total_score / len(news_items) if len(news_items) > 0 else 0.0
    
    def _fetch_and_analyze_news_sentiment(self, tickers: List[str]) -> Dict:
        """Fetch and analyze news sentiment using NewsAPI."""
        try:
            from newsapi import NewsApiClient
            
            # Initialize client (would need actual API key in production)
            newsapi = NewsApiClient(api_key='YOUR_API_KEY')
            
            sentiment_scores = {}
            for ticker in tickers:
                try:
                    # Search for news about the ticker
                    news = newsapi.get_everything(
                        q=ticker,
                        language='en',
                        sort_by='relevancy',
                        page_size=10
                    )
                    
                    if news['status'] == 'ok' and news['totalResults'] > 0:
                        score = self._calculate_news_sentiment(news['articles'])
                        sentiment_scores[ticker] = score
                    else:
                        sentiment_scores[ticker] = 0.0
                        
                except Exception as e:
                    sentiment_scores[ticker] = 0.0
            
            return sentiment_scores
            
        except Exception as e:
            return self._generate_synthetic_sentiment(tickers)
    
    def _generate_synthetic_sentiment(self, tickers: List[str]) -> Dict:
        """Generate synthetic sentiment scores for demonstration."""
        np.random.seed(42)
        return {ticker: np.random.uniform(-1, 1) for ticker in tickers}
    
    def _calculate_sentiment_adjustments(self, sentiment_scores: Dict) -> Dict:
        """Calculate portfolio adjustments based on sentiment."""
        adjustments = {}
        
        for ticker, score in sentiment_scores.items():
            if score > 0.3:
                adjustments[ticker] = {'action': 'overweight', 'adjustment': 0.1}
            elif score < -0.3:
                adjustments[ticker] = {'action': 'underweight', 'adjustment': -0.1}
            else:
                adjustments[ticker] = {'action': 'neutral', 'adjustment': 0.0}
        
        return adjustments
    
    def _generate_sentiment_recommendations(self, sentiment_scores: Dict) -> List[str]:
        """Generate trading recommendations based on sentiment."""
        recommendations = []
        
        # Sort by sentiment
        sorted_scores = sorted(sentiment_scores.items(), key=lambda x: x[1], reverse=True)
        
        # Top 3 positive
        for ticker, score in sorted_scores[:3]:
            if score > 0.2:
                recommendations.append(f"Consider overweighting {ticker} (sentiment: {score:.2f})")
        
        # Bottom 3 negative
        for ticker, score in sorted_scores[-3:]:
            if score < -0.2:
                recommendations.append(f"Consider underweighting {ticker} (sentiment: {score:.2f})")
        
        return recommendations
    
    def _calculate_sentiment_confidence(self, sentiment_scores: Dict) -> float:
        """Calculate confidence level of sentiment analysis."""
        if not sentiment_scores:
            return 0.0
        
        # Confidence based on dispersion of scores
        scores = list(sentiment_scores.values())
        if len(scores) < 2:
            return 0.5
        
        dispersion = np.std(scores)
        max_possible_dispersion = 2.0  # For scores between -1 and 1
        
        confidence = 1.0 - (dispersion / max_possible_dispersion)
        return max(0.0, min(1.0, confidence))
    
    def _generate_synthetic_sentiment_analysis(self, tickers: List[str]) -> Dict:
        """Generate synthetic sentiment analysis for fallback."""
        sentiment_scores = self._generate_synthetic_sentiment(tickers)
        
        return {
            'sentiment_scores': sentiment_scores,
            'adjustments': self._calculate_sentiment_adjustments(sentiment_scores),
            'recommendations': self._generate_sentiment_recommendations(sentiment_scores),
            'confidence': self._calculate_sentiment_confidence(sentiment_scores),
            'method': 'synthetic'
        }

# Initialize ML engine
ml_engine = MachineLearningEngine()

# ============================================================================
# 3. ADVANCED BACKTESTING ENGINE
# ============================================================================

class AdvancedBacktestingEngine:
    """Advanced backtesting engine with multiple strategies and walk-forward analysis."""
    
    def __init__(self):
        self.strategies = {}
        self.backtest_results = {}
        self.performance_metrics = {}
        self.walk_forward_windows = {}
        
    def run_comprehensive_backtest(self, returns: pd.DataFrame,
                                 weights: Dict,
                                 benchmark_returns: pd.Series,
                                 initial_capital: float = 1000000) -> Dict:
        """Run comprehensive backtesting with multiple strategies."""
        try:
            performance_monitor.start_operation('comprehensive_backtesting')
            
            results = {
                'portfolio_evolution': {},
                'strategy_comparison': {},
                'performance_metrics': {},
                'risk_analysis': {},
                'attribution_analysis': {}
            }
            
            # Convert weights to array
            weights_array = np.array(list(weights.values()))
            
            # Calculate portfolio returns
            portfolio_returns = returns.dot(weights_array)
            
            # 1. Simple buy-and-hold strategy
            buy_hold_results = self._run_buy_hold_backtest(
                portfolio_returns, initial_capital
            )
            
            # 2. Rebalancing strategies
            rebalancing_results = self._run_rebalancing_backtests(
                returns, weights, initial_capital
            )
            
            # 3. Market timing strategies
            timing_results = self._run_market_timing_backtests(
                portfolio_returns, initial_capital
            )
            
            # 4. Walk-forward optimization
            walk_forward_results = self._run_walk_forward_backtest(
                returns, initial_capital
            )
            
            # Combine results
            results['portfolio_evolution'] = buy_hold_results['portfolio_values']
            results['strategy_comparison'] = {
                'buy_hold': buy_hold_results['metrics'],
                'quarterly_rebalancing': rebalancing_results.get('quarterly', {}),
                'market_timing': timing_results.get('simple_moving_average', {}),
                'walk_forward': walk_forward_results.get('metrics', {})
            }
            
            # Calculate comprehensive metrics
            results['performance_metrics'] = self._calculate_backtest_metrics(
                buy_hold_results['portfolio_values'],
                benchmark_returns,
                initial_capital
            )
            
            # Risk analysis
            results['risk_analysis'] = self._analyze_backtest_risk(
                buy_hold_results['portfolio_values'],
                portfolio_returns
            )
            
            # Attribution analysis
            results['attribution_analysis'] = self._perform_attribution_analysis(
                returns, weights_array, benchmark_returns
            )
            
            performance_monitor.end_operation('comprehensive_backtesting')
            return results
            
        except Exception as e:
            performance_monitor.end_operation('comprehensive_backtesting', {'error': str(e)})
            error_analyzer.analyze_error_with_context(e, {'operation': 'backtesting'})
            return self._create_fallback_backtest_results(returns, weights, initial_capital)
    
    def _run_buy_hold_backtest(self, portfolio_returns: pd.Series,
                             initial_capital: float) -> Dict:
        """Run simple buy-and-hold backtest."""
        portfolio_values = [initial_capital]
        
        for ret in portfolio_returns:
            new_value = portfolio_values[-1] * (1 + ret)
            portfolio_values.append(new_value)
        
        portfolio_series = pd.Series(portfolio_values[1:], index=portfolio_returns.index)
        
        return {
            'portfolio_values': portfolio_series,
            'metrics': self._calculate_strategy_metrics(portfolio_series, portfolio_returns)
        }
    
    def _run_rebalancing_backtests(self, returns: pd.DataFrame,
                                 weights: Dict,
                                 initial_capital: float) -> Dict:
        """Run backtests with different rebalancing frequencies."""
        strategies = ['monthly', 'quarterly', 'semi_annual', 'annual']
        results = {}
        
        for freq in strategies:
            try:
                portfolio_values = self._simulate_rebalancing(
                    returns, weights, initial_capital, freq
                )
                
                if not portfolio_values.empty:
                    portfolio_returns = portfolio_values.pct_change().dropna()
                    results[freq] = self._calculate_strategy_metrics(
                        portfolio_values, portfolio_returns
                    )
            except Exception as e:
                continue
        
        return results
    
    def _simulate_rebalancing(self, returns: pd.DataFrame,
                            weights: Dict,
                            initial_capital: float,
                            frequency: str) -> pd.Series:
        """Simulate portfolio rebalancing."""
        # Convert frequency to days
        freq_map = {
            'monthly': 21,
            'quarterly': 63,
            'semi_annual': 126,
            'annual': 252
        }
        
        rebalance_interval = freq_map.get(frequency, 63)
        
        # Initialize
        current_weights = np.array(list(weights.values()))
        portfolio_value = initial_capital
        portfolio_values = []
        dates = []
        
        # Convert weights to dollar amounts
        dollar_weights = current_weights * portfolio_value
        
        for i in range(len(returns)):
            date = returns.index[i]
            daily_returns = returns.iloc[i].values
            
            # Update dollar amounts based on returns
            dollar_weights *= (1 + daily_returns)
            portfolio_value = dollar_weights.sum()
            
            # Rebalance if it's time
            if i % rebalance_interval == 0 and i > 0:
                dollar_weights = current_weights * portfolio_value
            
            portfolio_values.append(portfolio_value)
            dates.append(date)
        
        return pd.Series(portfolio_values, index=dates)
    
    def _run_market_timing_backtests(self, portfolio_returns: pd.Series,
                                   initial_capital: float) -> Dict:
        """Run market timing strategy backtests."""
        strategies = {
            'simple_moving_average': self._sma_timing_strategy,
            'momentum': self._momentum_timing_strategy,
            'mean_reversion': self._mean_reversion_strategy,
            'volatility_adjusted': self._volatility_timing_strategy
        }
        
        results = {}
        
        for name, strategy_func in strategies.items():
            try:
                signals = strategy_func(portfolio_returns)
                portfolio_values = self._apply_timing_strategy(
                    portfolio_returns, signals, initial_capital
                )
                
                if not portfolio_values.empty:
                    strategy_returns = portfolio_values.pct_change().dropna()
                    results[name] = self._calculate_strategy_metrics(
                        portfolio_values, strategy_returns
                    )
            except Exception as e:
                continue
        
        return results
    
    def _sma_timing_strategy(self, returns: pd.Series) -> pd.Series:
        """Simple Moving Average timing strategy."""
        short_window = 50
        long_window = 200
        
        if len(returns) < long_window:
            return pd.Series(1, index=returns.index)  # Always invested
        
        # Calculate cumulative returns for price series
        prices = (1 + returns).cumprod()
        
        short_sma = prices.rolling(window=short_window).mean()
        long_sma = prices.rolling(window=long_window).mean()
        
        # Generate signals (1 = invested, 0 = cash)
        signals = (short_sma > long_sma).astype(int)
        signals = signals.fillna(1)  # Invested by default
        
        return signals
    
    def _momentum_timing_strategy(self, returns: pd.Series) -> pd.Series:
        """Momentum-based timing strategy."""
        lookback = 60
        holding_period = 20
        
        if len(returns) < lookback:
            return pd.Series(1, index=returns.index)
        
        momentum = returns.rolling(window=lookback).mean()
        
        # Simple momentum strategy
        signals = (momentum > 0).astype(int)
        
        # Add holding period logic
        signals = signals.rolling(window=holding_period).max()
        signals = signals.fillna(1)
        
        return signals
    
    def _mean_reversion_strategy(self, returns: pd.Series) -> pd.Series:
        """Mean reversion timing strategy."""
        lookback = 20
        zscore_threshold = 1.0
        
        if len(returns) < lookback:
            return pd.Series(1, index=returns.index)
        
        rolling_mean = returns.rolling(window=lookback).mean()
        rolling_std = returns.rolling(window=lookback).std()
        
        zscores = (returns - rolling_mean) / rolling_std
        
        # Buy when oversold (zscore < -threshold), sell when overbought (zscore > threshold)
        signals = pd.Series(1, index=returns.index)
        signals[zscores > zscore_threshold] = 0  # Move to cash when overbought
        signals[zscores < -zscore_threshold] = 1  # Invest when oversold
        
        signals = signals.fillna(1)
        
        return signals
    
    def _volatility_timing_strategy(self, returns: pd.Series) -> pd.Series:
        """Volatility-adjusted timing strategy."""
        vol_window = 20
        vol_threshold = 0.02  # 2% daily volatility
        
        if len(returns) < vol_window:
            return pd.Series(1, index=returns.index)
        
        volatility = returns.rolling(window=vol_window).std()
        
        # Reduce exposure during high volatility
        signals = pd.Series(1, index=returns.index)
        signals[volatility > vol_threshold] = 0.5  # Reduce to 50% exposure
        signals[volatility > vol_threshold * 1.5] = 0.25  # Reduce further
        
        return signals
    
    def _apply_timing_strategy(self, returns: pd.Series,
                             signals: pd.Series,
                             initial_capital: float) -> pd.Series:
        """Apply timing strategy to generate portfolio values."""
        if len(returns) != len(signals):
            raise ValueError("Returns and signals must have same length")
        
        portfolio_value = initial_capital
        portfolio_values = []
        cash_return = 0.0001  # Assume small return on cash
        
        for i in range(len(returns)):
            signal = signals.iloc[i] if i < len(signals) else 1
            
            # Calculate portfolio return
            if signal > 0:
                # Partially or fully invested
                portfolio_return = returns.iloc[i] * signal + cash_return * (1 - signal)
            else:
                # In cash
                portfolio_return = cash_return
            
            portfolio_value *= (1 + portfolio_return)
            portfolio_values.append(portfolio_value)
        
        return pd.Series(portfolio_values, index=returns.index)
    
    def _run_walk_forward_backtest(self, returns: pd.DataFrame,
                                 initial_capital: float) -> Dict:
        """Run walk-forward optimization backtest."""
        try:
            # Split data into in-sample and out-of-sample periods
            total_days = len(returns)
            window_size = 252 * 2  # 2 years for training
            test_size = 63  # 3 months for testing
            
            portfolio_values = []
            all_dates = []
            
            for start_idx in range(0, total_days - window_size - test_size, test_size):
                # Training window
                train_end = start_idx + window_size
                train_data = returns.iloc[start_idx:train_end]
                
                # Testing window
                test_start = train_end
                test_end = test_start + test_size
                test_data = returns.iloc[test_start:test_end]
                
                if len(train_data) < 100 or len(test_data) < 10:
                    continue
                
                # Optimize portfolio on training data
                try:
                    mu_train = train_data.mean() * 252
                    S_train = train_data.cov() * 252
                    
                    # Simple max Sharpe optimization
                    n_assets = len(mu_train)
                    
                    def objective(weights):
                        port_return = np.dot(weights, mu_train)
                        port_risk = np.sqrt(weights.T @ S_train @ weights)
                        if port_risk == 0:
                            return 1e10
                        return -port_return / port_risk
                    
                    bounds = [(0, 1) for _ in range(n_assets)]
                    constraints = [{'type': 'eq', 'fun': lambda w: np.sum(w) - 1}]
                    
                    initial_weights = np.ones(n_assets) / n_assets
                    
                    result = optimize.minimize(
                        objective,
                        initial_weights,
                        bounds=bounds,
                        constraints=constraints,
                        method='SLSQP'
                    )
                    
                    if result.success:
                        weights = result.x
                        weights = weights / weights.sum()
                        
                        # Apply weights to test period
                        test_returns = test_data.dot(weights)
                        
                        # Calculate portfolio values for this window
                        if not portfolio_values:
                            window_value = initial_capital
                        else:
                            window_value = portfolio_values[-1]
                        
                        for ret in test_returns:
                            window_value *= (1 + ret)
                            portfolio_values.append(window_value)
                            all_dates.append(test_data.index[list(test_returns).index(ret)])
                            
                except Exception as e:
                    continue
            
            if portfolio_values:
                portfolio_series = pd.Series(portfolio_values, index=all_dates)
                portfolio_returns = portfolio_series.pct_change().dropna()
                
                return {
                    'portfolio_values': portfolio_series,
                    'metrics': self._calculate_strategy_metrics(portfolio_series, portfolio_returns)
                }
        
        except Exception as e:
            pass
        
        return {}
    
    def _calculate_strategy_metrics(self, portfolio_values: pd.Series,
                                  portfolio_returns: pd.Series) -> Dict:
        """Calculate performance metrics for a strategy."""
        if len(portfolio_values) < 2 or len(portfolio_returns) < 1:
            return {}
        
        total_return = (portfolio_values.iloc[-1] / portfolio_values.iloc[0]) - 1
        annual_return = ((1 + total_return) ** (252 / len(portfolio_values))) - 1
        volatility = portfolio_returns.std() * np.sqrt(252)
        
        # Calculate Sharpe ratio (assuming 0% risk-free for simplicity)
        sharpe = annual_return / volatility if volatility > 0 else 0
        
        # Maximum drawdown
        cumulative = (1 + portfolio_returns).cumprod()
        rolling_max = cumulative.expanding().max()
        drawdown = (cumulative - rolling_max) / rolling_max
        max_drawdown = drawdown.min()
        
        # Calculate Sortino ratio (downside risk)
        downside_returns = portfolio_returns[portfolio_returns < 0]
        downside_vol = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0
        sortino = annual_return / downside_vol if downside_vol > 0 else 0
        
        # Calmar ratio
        calmar = annual_return / abs(max_drawdown) if max_drawdown < 0 else 0
        
        # Win rate
        win_rate = (portfolio_returns > 0).mean()
        
        # Average win/loss
        avg_win = portfolio_returns[portfolio_returns > 0].mean() if len(portfolio_returns[portfolio_returns > 0]) > 0 else 0
        avg_loss = portfolio_returns[portfolio_returns < 0].mean() if len(portfolio_returns[portfolio_returns < 0]) > 0 else 0
        
        return {
            'total_return': total_return,
            'annual_return': annual_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe,
            'max_drawdown': max_drawdown,
            'sortino_ratio': sortino,
            'calmar_ratio': calmar,
            'win_rate': win_rate,
            'avg_win': avg_win,
            'avg_loss': avg_loss,
            'profit_factor': abs(avg_win / avg_loss) if avg_loss != 0 else float('inf')
        }
    
    def _calculate_backtest_metrics(self, portfolio_values: pd.Series,
                                  benchmark_returns: pd.Series,
                                  initial_capital: float) -> Dict:
        """Calculate comprehensive backtest metrics."""
        if len(portfolio_values) < 2:
            return {}
        
        # Portfolio returns
        portfolio_returns = portfolio_values.pct_change().dropna()
        
        # Align benchmark returns
        benchmark_aligned = benchmark_returns.reindex(portfolio_returns.index).fillna(0)
        
        # Basic metrics
        total_return = (portfolio_values.iloc[-1] / initial_capital) - 1
        annual_return = ((1 + total_return) ** (252 / len(portfolio_values))) - 1
        
        # Risk metrics
        volatility = portfolio_returns.std() * np.sqrt(252)
        
        # Benchmark metrics
        if not benchmark_aligned.empty:
            benchmark_cumulative = (1 + benchmark_aligned).cumprod()
            benchmark_return = benchmark_cumulative.iloc[-1] - 1 if len(benchmark_cumulative) > 0 else 0
            
            # Alpha and Beta
            try:
                cov_matrix = np.cov(portfolio_returns, benchmark_aligned)
                beta = cov_matrix[0, 1] / cov_matrix[1, 1] if cov_matrix[1, 1] != 0 else 0
                alpha = annual_return - beta * (benchmark_return * 252 / len(portfolio_values))
            except:
                beta = 0
                alpha = 0
            
            # Tracking error
            tracking_error = (portfolio_returns - benchmark_aligned).std() * np.sqrt(252)
            
            # Information ratio
            excess_returns = portfolio_returns - benchmark_aligned
            information_ratio = excess_returns.mean() / excess_returns.std() * np.sqrt(252) if excess_returns.std() > 0 else 0
        else:
            benchmark_return = 0
            beta = 0
            alpha = 0
            tracking_error = 0
            information_ratio = 0
        
        # Downside metrics
        downside_returns = portfolio_returns[portfolio_returns < 0]
        downside_vol = downside_returns.std() * np.sqrt(252) if len(downside_returns) > 0 else 0
        
        # Maximum drawdown
        cumulative = (1 + portfolio_returns).cumprod()
        rolling_max = cumulative.expanding().max()
        drawdown = (cumulative - rolling_max) / rolling_max
        max_drawdown = drawdown.min()
        
        # Recovery metrics
        recovery_time = self._calculate_recovery_time(drawdown)
        
        # Sharpe and Sortino ratios
        sharpe = annual_return / volatility if volatility > 0 else 0
        sortino = annual_return / downside_vol if downside_vol > 0 else 0
        
        # Calmar ratio
        calmar = annual_return / abs(max_drawdown) if max_drawdown < 0 else 0
        
        return {
            'total_return': total_return,
            'annual_return': annual_return,
            'volatility': volatility,
            'sharpe_ratio': sharpe,
            'sortino_ratio': sortino,
            'calmar_ratio': calmar,
            'max_drawdown': max_drawdown,
            'recovery_time_days': recovery_time,
            'alpha': alpha,
            'beta': beta,
            'tracking_error': tracking_error,
            'information_ratio': information_ratio,
            'benchmark_return': benchmark_return,
            'excess_return': total_return - benchmark_return
        }
    
    def _calculate_recovery_time(self, drawdown: pd.Series) -> float:
        """Calculate average recovery time from drawdowns."""
        if len(drawdown) == 0:
            return 0
        
        recovery_times = []
        in_drawdown = False
        drawdown_start = 0
        
        for i in range(len(drawdown)):
            if drawdown.iloc[i] < -0.05:  # 5% drawdown threshold
                if not in_drawdown:
                    in_drawdown = True
                    drawdown_start = i
            else:
                if in_drawdown:
                    in_drawdown = False
                    recovery_time = i - drawdown_start
                    recovery_times.append(recovery_time)
        
        return np.mean(recovery_times) if recovery_times else 0
    
    def _analyze_backtest_risk(self, portfolio_values: pd.Series,
                             portfolio_returns: pd.Series) -> Dict:
        """Analyze backtest risk metrics."""
        if len(portfolio_returns) < 1:
            return {}
        
        # VaR and CVaR calculations
        var_95 = -np.percentile(portfolio_returns, 5)
        cvar_95_data = portfolio_returns[portfolio_returns <= -var_95]
        cvar_95 = -cvar_95_data.mean() if len(cvar_95_data) > 0 else var_95
        
        var_99 = -np.percentile(portfolio_returns, 1)
        cvar_99_data = portfolio_returns[portfolio_returns <= -var_99]
        cvar_99 = -cvar_99_data.mean() if len(cvar_99_data) > 0 else var_99
        
        # Tail risk metrics
        skewness = portfolio_returns.skew()
        kurt = portfolio_returns.kurtosis()
        
        # Drawdown analysis
        cumulative = (1 + portfolio_returns).cumprod()
        rolling_max = cumulative.expanding().max()
        drawdown = (cumulative - rolling_max) / rolling_max
        
        # Drawdown statistics
        max_dd = drawdown.min()
        avg_dd = drawdown.mean()
        dd_duration = (drawdown < 0).sum()
        
        # Stress periods identification
        stress_periods = self._identify_stress_periods(portfolio_returns)
        
        # Liquidity risk (simplified)
        liquidity_risk = self._estimate_liquidity_risk(portfolio_returns)
        
        return {
            'var_95': var_95,
            'cvar_95': cvar_95,
            'var_99': var_99,
            'cvar_99': cvar_99,
            'skewness': skewness,
            'kurtosis': kurt,
            'max_drawdown': max_dd,
            'average_drawdown': avg_dd,
            'drawdown_duration': dd_duration,
            'stress_periods': stress_periods,
            'liquidity_risk_score': liquidity_risk,
            'tail_risk_ratio': cvar_95 / var_95 if var_95 != 0 else 0
        }
    
    def _identify_stress_periods(self, returns: pd.Series,
                               window: int = 20,
                               threshold: float = -0.02) -> List[Dict]:
        """Identify stress periods in the backtest."""
        stress_periods = []
        
        rolling_vol = returns.rolling(window=window).std()
        vol_threshold = rolling_vol.quantile(0.75)
        
        in_stress = False
        stress_start = None
        
        for i in range(window, len(returns)):
            # Check for stress conditions
            is_high_vol = rolling_vol.iloc[i] > vol_threshold
            is_large_loss = returns.iloc[i] < threshold
            
            if (is_high_vol or is_large_loss) and not in_stress:
                in_stress = True
                stress_start = returns.index[i]
            
            elif not (is_high_vol or is_large_loss) and in_stress:
                in_stress = False
                stress_end = returns.index[i-1]
                
                stress_periods.append({
                    'start': stress_start,
                    'end': stress_end,
                    'duration': (stress_end - stress_start).days,
                    'max_loss': returns.loc[stress_start:stress_end].min(),
                    'volatility': returns.loc[stress_start:stress_end].std()
                })
        
        return stress_periods
    
    def _estimate_liquidity_risk(self, returns: pd.Series) -> float:
        """Estimate liquidity risk from returns pattern."""
        try:
            # Simplified liquidity risk estimation
            # Based on autocorrelation and volatility patterns
            autocorr_lag1 = returns.autocorr(lag=1)
            autocorr_lag5 = returns.autocorr(lag=5)
            
            # High positive autocorrelation might indicate illiquidity
            liquidity_score = 1 - (abs(autocorr_lag1) + abs(autocorr_lag5)) / 2
            
            return max(0, min(1, liquidity_score))
        except:
            return 0.5
    
    def _perform_attribution_analysis(self, returns: pd.DataFrame,
                                    weights: np.ndarray,
                                    benchmark_returns: pd.Series) -> Dict:
        """Perform performance attribution analysis."""
        try:
            if len(returns.columns) != len(weights):
                return {}
            
            # Calculate portfolio returns
            portfolio_returns = returns.dot(weights)
            
            # Align benchmark
            benchmark_aligned = benchmark_returns.reindex(portfolio_returns.index).fillna(0)
            
            # Brinson-Fachler attribution (simplified)
            attribution = {}
            
            for i, asset in enumerate(returns.columns):
                asset_return = returns[asset]
                asset_weight = weights[i]
                
                # Allocation effect
                allocation = (asset_weight - 1/len(weights)) * (benchmark_aligned - benchmark_aligned.mean())
                
                # Selection effect
                selection = asset_weight * (asset_return - benchmark_aligned)
                
                attribution[asset] = {
                    'weight': asset_weight,
                    'return': asset_return.mean() * 252,
                    'allocation_effect': allocation.mean() * 252,
                    'selection_effect': selection.mean() * 252,
                    'interaction_effect': (asset_weight - 1/len(weights)) * (asset_return - benchmark_aligned).mean() * 252
                }
            
            # Total attribution
            total_allocation = sum([attr['allocation_effect'] for attr in attribution.values()])
            total_selection = sum([attr['selection_effect'] for attr in attribution.values()])
            total_interaction = sum([attr['interaction_effect'] for attr in attribution.values()])
            
            return {
                'asset_level': attribution,
                'total': {
                    'allocation': total_allocation,
                    'selection': total_selection,
                    'interaction': total_interaction,
                    'total_active': total_allocation + total_selection + total_interaction
                }
            }
            
        except Exception as e:
            return {}
    
    def _create_fallback_backtest_results(self, returns: pd.DataFrame,
                                        weights: Dict,
                                        initial_capital: float) -> Dict:
        """Create fallback backtest results."""
        try:
            weights_array = np.array(list(weights.values()))
            portfolio_returns = returns.dot(weights_array)
            
            portfolio_values = [initial_capital]
            for ret in portfolio_returns:
                portfolio_values.append(portfolio_values[-1] * (1 + ret))
            
            portfolio_series = pd.Series(portfolio_values[1:], index=portfolio_returns.index)
            
            return {
                'portfolio_evolution': portfolio_series,
                'strategy_comparison': {
                    'buy_hold': self._calculate_strategy_metrics(portfolio_series, portfolio_returns)
                },
                'performance_metrics': self._calculate_backtest_metrics(
                    portfolio_series, pd.Series(0, index=portfolio_returns.index), initial_capital
                ),
                'risk_analysis': self._analyze_backtest_risk(portfolio_series, portfolio_returns),
                'attribution_analysis': {}
            }
        except Exception as e:
            return {
                'portfolio_evolution': pd.Series(),
                'strategy_comparison': {},
                'performance_metrics': {},
                'risk_analysis': {},
                'attribution_analysis': {}
            }
    
    def generate_backtest_report(self, backtest_results: Dict,
                               report_format: str = 'html') -> str:
        """Generate comprehensive backtest report."""
        try:
            performance_monitor.start_operation('backtest_report_generation')
            
            if report_format == 'html':
                report = self._generate_html_report(backtest_results)
            elif report_format == 'text':
                report = self._generate_text_report(backtest_results)
            else:
                report = self._generate_markdown_report(backtest_results)
            
            performance_monitor.end_operation('backtest_report_generation')
            return report
            
        except Exception as e:
            performance_monitor.end_operation('backtest_report_generation', {'error': str(e)})
            return "Error generating backtest report"
    
    def _generate_html_report(self, results: Dict) -> str:
        """Generate HTML backtest report."""
        html = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>QuantEdge Pro Backtest Report</title>
            <style>
                body { font-family: Arial, sans-serif; margin: 40px; color: #333; }
                .header { background: linear-gradient(135deg, #00cc96, #636efa); color: white; padding: 30px; border-radius: 10px; }
                .section { margin: 30px 0; padding: 20px; border: 1px solid #ddd; border-radius: 5px; }
                .metric-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; }
                .metric-card { background: #f5f5f5; padding: 15px; border-radius: 5px; text-align: center; }
                .metric-value { font-size: 24px; font-weight: bold; color: #00cc96; }
                .metric-label { font-size: 12px; color: #666; text-transform: uppercase; }
                table { width: 100%; border-collapse: collapse; }
                th, td { padding: 12px; text-align: left; border-bottom: 1px solid #ddd; }
                th { background-color: #f2f2f2; }
                .positive { color: #00cc96; }
                .negative { color: #ef553b; }
            </style>
        </head>
        <body>
            <div class="header">
                <h1> QuantEdge Pro Backtest Report</h1>
                <p>Generated on {date}</p>
            </div>
        """.format(date=datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
        
        # Add performance metrics
        if 'performance_metrics' in results:
            metrics = results['performance_metrics']
            html += """
            <div class="section">
                <h2> Performance Metrics</h2>
                <div class="metric-grid">
            """
            
            metric_items = [
                ('Total Return', metrics.get('total_return', 0), 'percent'),
                ('Annual Return', metrics.get('annual_return', 0), 'percent'),
                ('Sharpe Ratio', metrics.get('sharpe_ratio', 0), 'number'),
                ('Max Drawdown', metrics.get('max_drawdown', 0), 'percent'),
                ('Volatility', metrics.get('volatility', 0), 'percent'),
                ('Alpha', metrics.get('alpha', 0), 'number'),
                ('Beta', metrics.get('beta', 0), 'number')
            ]
            
            for label, value, fmt in metric_items:
                if fmt == 'percent':
                    display_value = f"{value:.2%}"
                    css_class = 'positive' if value > 0 else 'negative'
                else:
                    display_value = f"{value:.3f}"
                    css_class = 'positive' if value > 0 else 'negative'
                
                html += f"""
                <div class="metric-card">
                    <div class="metric-value {css_class}">{display_value}</div>
                    <div class="metric-label">{label}</div>
                </div>
                """
            
            html += """
                </div>
            </div>
            """
        
        # Add strategy comparison
        if 'strategy_comparison' in results:
            html += """
            <div class="section">
                <h2> Strategy Comparison</h2>
                <table>
                    <tr>
                        <th>Strategy</th>
                        <th>Annual Return</th>
                        <th>Sharpe Ratio</th>
                        <th>Max Drawdown</th>
                        <th>Win Rate</th>
                    </tr>
            """
            
            for strategy, metrics in results['strategy_comparison'].items():
                html += f"""
                <tr>
                    <td>{strategy.replace('_', ' ').title()}</td>
                    <td class="{ 'positive' if metrics.get('annual_return', 0) > 0 else 'negative' }">{metrics.get('annual_return', 0):.2%}</td>
                    <td>{metrics.get('sharpe_ratio', 0):.3f}</td>
                    <td class="{ 'positive' if metrics.get('max_drawdown', 0) >= -0.1 else 'negative' }">{metrics.get('max_drawdown', 0):.2%}</td>
                    <td>{metrics.get('win_rate', 0):.1%}</td>
                </tr>
                """
            
            html += """
                </table>
            </div>
            """
        
        # Add risk analysis
        if 'risk_analysis' in results:
            risk = results['risk_analysis']
            html += """
            <div class="section">
                <h2> Risk Analysis</h2>
                <div class="metric-grid">
            """
            
            risk_items = [
                ('VaR 95%', risk.get('var_95', 0), 'percent'),
                ('CVaR 95%', risk.get('cvar_95', 0), 'percent'),
                ('Tail Risk Ratio', risk.get('tail_risk_ratio', 0), 'number'),
                ('Skewness', risk.get('skewness', 0), 'number'),
                ('Kurtosis', risk.get('kurtosis', 0), 'number')
            ]
            
            for label, value, fmt in risk_items:
                if fmt == 'percent':
                    display_value = f"{value:.3%}"
                else:
                    display_value = f"{value:.3f}"
                
                html += f"""
                <div class="metric-card">
                    <div class="metric-value">{display_value}</div>
                    <div class="metric-label">{label}</div>
                </div>
                """
            
            html += """
                </div>
            </div>
            """
        
        html += """
            <div class="section">
                <p style="text-align: center; color: #666; font-size: 12px;">
                    Generated by QuantEdge Pro v5.0 Enterprise Edition<br>
                    Report ID: {report_id}
                </p>
            </div>
        </body>
        </html>
        """.format(report_id=hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8])
        
        return html
    
    def _generate_text_report(self, results: Dict) -> str:
        """Generate plain text backtest report."""
        report = f"""
        =================================================================
        QUANTEDGE PRO BACKTEST REPORT
        Generated: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
        Report ID: {hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8]}
        =================================================================
        
        PERFORMANCE METRICS
        =================================================================
        """
        
        if 'performance_metrics' in results:
            metrics = results['performance_metrics']
            for key, value in metrics.items():
                if isinstance(value, float):
                    if 'return' in key.lower() or 'drawdown' in key.lower():
                        report += f"{key:25} {value:>10.2%}\n"
                    else:
                        report += f"{key:25} {value:>10.3f}\n"
                else:
                    report += f"{key:25} {value:>10}\n"
        
        report += """
        
        STRATEGY COMPARISON
        =================================================================
        """
        
        if 'strategy_comparison' in results:
            for strategy, strategy_metrics in results['strategy_comparison'].items():
                report += f"\n{strategy.replace('_', ' ').upper()}:\n"
                for key, value in strategy_metrics.items():
                    if isinstance(value, float):
                        report += f"  {key:20} {value:>10.3f}\n"
        
        report += """
        
        RISK ANALYSIS
        =================================================================
        """
        
        if 'risk_analysis' in results:
            risk = results['risk_analysis']
            for key, value in risk.items():
                if isinstance(value, float):
                    report += f"{key:25} {value:>10.3f}\n"
        
        report += """
        =================================================================
        END OF REPORT
        =================================================================
        """
        
        return report
    
    def _generate_markdown_report(self, results: Dict) -> str:
        """Generate markdown backtest report."""
        report = f"""# QuantEdge Pro Backtest Report
        
**Generated:** {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}  
**Report ID:** {hashlib.md5(str(datetime.now()).encode()).hexdigest()[:8]}
        
##  Performance Metrics
        
| Metric | Value |
|--------|-------|
"""
        
        if 'performance_metrics' in results:
            metrics = results['performance_metrics']
            for key, value in metrics.items():
                if isinstance(value, float):
                    if 'return' in key.lower() or 'drawdown' in key.lower():
                        report += f"| {key} | {value:.2%} |\n"
                    else:
                        report += f"| {key} | {value:.3f} |\n"
                else:
                    report += f"| {key} | {value} |\n"
        
        report += """
        
##  Strategy Comparison
        
| Strategy | Annual Return | Sharpe Ratio | Max Drawdown |
|----------|--------------|--------------|--------------|
"""
        
        if 'strategy_comparison' in results:
            for strategy, strategy_metrics in results['strategy_comparison'].items():
                report += f"| {strategy.replace('_', ' ').title()} | {strategy_metrics.get('annual_return', 0):.2%} | {strategy_metrics.get('sharpe_ratio', 0):.3f} | {strategy_metrics.get('max_drawdown', 0):.2%} |\n"
        
        report += """
        
##  Risk Metrics
        
| Metric | Value |
|--------|-------|
"""
        
        if 'risk_analysis' in results:
            risk = results['risk_analysis']
            for key, value in risk.items():
                if isinstance(value, float):
                    report += f"| {key} | {value:.3f} |\n"
        
        report += f"""
        
---
*Generated by QuantEdge Pro v5.0 Enterprise Edition*
"""
        
        return report

# Initialize advanced backtesting engine
backtesting_engine = AdvancedBacktestingEngine()

# ============================================================================
# 4. ENTERPRISE REPORTING SYSTEM
# ============================================================================

class EnterpriseReportingSystem:
    """Enterprise-grade reporting system with multiple output formats."""
    
    def __init__(self):
        self.report_templates = {}
        self.report_history = []
        self.max_reports = 100
        
    def generate_comprehensive_report(self, analysis_results: Dict,
                                    report_type: str = 'executive',
                                    format: str = 'html') -> Dict:
        """Generate comprehensive enterprise report."""
        try:
            performance_monitor.start_operation('enterprise_report_generation')
            
            report_id = f"REP_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{random.randint(1000, 9999)}"
            
            if report_type == 'executive':
                report = self._generate_executive_report(analysis_results, format)
            elif report_type == 'detailed':
                report = self._generate_detailed_report(analysis_results, format)
            elif report_type == 'regulatory':
                report = self._generate_regulatory_report(analysis_results, format)
            elif report_type == 'risk':
                report = self._generate_risk_report(analysis_results, format)
            else:
                report = self._generate_executive_report(analysis_results, format)
            
            # Store report in history
            report_record = {
                'report_id': report_id,
                'timestamp': datetime.now().isoformat(),
                'type': report_type,
                'format': format,
                'size': len(str(report)) if isinstance(report, (str, bytes)) else 0,
                'metadata': {
                    'generator': 'QuantEdge Pro v5.0',
                    'version': '5.0.0'
                }
            }
            
            self.report_history.append(report_record)
            if len(self.report_history) > self.max_reports:
                self.report_history.pop(0)
            
            performance_monitor.end_operation('enterprise_report_generation', {
                'report_id': report_id,
                'report_type': report_type
            })
            
            return {
                'report_id': report_id,
                'content': report,
                'format': format,
                'timestamp': datetime.now().isoformat(),
                'metadata': report_record['metadata']
            }
            
        except Exception as e:
            performance_monitor.end_operation('enterprise_report_generation', {'error': str(e)})
            error_analyzer.analyze_error_with_context(e, {'operation': 'report_generation'})
            return self._generate_error_report(e, format)
    
    def _generate_executive_report(self, results: Dict, format: str) -> Any:
        """Generate executive summary report."""
        if format == 'html':
            return self._generate_executive_html_report(results)
        elif format == 'pdf':
            return self._generate_pdf_report(results, 'executive')
        elif format == 'excel':
            return self._generate_excel_report(results, 'executive')
        else:
            return self._generate_executive_text_report(results)
    
    def _generate_executive_html_report(self, results: Dict) -> str:
        """Generate HTML executive report."""
        html = """
        <!DOCTYPE html>
        <html>
        <head>
            <title>QuantEdge Pro Executive Report</title>
            <style>
                :root {
                    --primary-color: #00cc96;
                    --secondary-color: #636efa;
                    --accent-color: #ff6b6b;
                    --text-color: #333;
                    --light-bg: #f8f9fa;
                    --dark-bg: #1a1d2e;
                }
                
                body {
                    font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
                    margin: 0;
                    padding: 0;
                    background: var(--light-bg);
                    color: var(--text-color);
                }
                
                .report-container {
                    max-width: 1200px;
                    margin: 0 auto;
                    padding: 20px;
                }
                
                .report-header {
                    background: linear-gradient(135deg, var(--dark-bg), #2d3748);
                    color: white;
                    padding: 40px;
                    border-radius: 15px;
                    margin-bottom: 30px;
                    box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
                }
                
                .report-title {
                    font-size: 2.8rem;
                    font-weight: 800;
                    margin-bottom: 10px;
                    background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
                    -webkit-background-clip: text;
                    -webkit-text-fill-color: transparent;
                    background-clip: text;
                }
                
                .report-subtitle {
                    font-size: 1.2rem;
                    opacity: 0.9;
                    margin-bottom: 20px;
                }
                
                .report-metadata {
                    display: flex;
                    gap: 30px;
                    font-size: 0.9rem;
                    opacity: 0.8;
                }
                
                .section {
                    background: white;
                    padding: 30px;
                    border-radius: 15px;
                    margin-bottom: 30px;
                    box-shadow: 0 5px 15px rgba(0, 0, 0, 0.05);
                    border-left: 5px solid var(--primary-color);
                }
                
                .section-title {
                    font-size: 1.5rem;
                    font-weight: 700;
                    color: var(--dark-bg);
                    margin-bottom: 20px;
                    display: flex;
                    align-items: center;
                    gap: 10px;
                }
                
                .section-title::before {
                    content: '';
                    width: 8px;
                    height: 25px;
                    background: var(--primary-color);
                    border-radius: 4px;
                }
                
                .metrics-grid {
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
                    gap: 20px;
                    margin-bottom: 30px;
                }
                
                .metric-card {
                    background: linear-gradient(135deg, #f8f9fa, #e9ecef);
                    padding: 25px;
                    border-radius: 12px;
                    text-align: center;
                    transition: transform 0.3s ease, box-shadow 0.3s ease;
                    border: 1px solid rgba(0, 0, 0, 0.05);
                }
                
                .metric-card:hover {
                    transform: translateY(-5px);
                    box-shadow: 0 15px 30px rgba(0, 0, 0, 0.1);
                }
                
                .metric-value {
                    font-size: 2.2rem;
                    font-weight: 800;
                    margin-bottom: 10px;
                }
                
                .metric-value.positive { color: var(--primary-color); }
                .metric-value.negative { color: var(--accent-color); }
                .metric-value.neutral { color: var(--secondary-color); }
                
                .metric-label {
                    font-size: 0.9rem;
                    color: #666;
                    text-transform: uppercase;
                    letter-spacing: 1px;
                    font-weight: 600;
                }
                
                .metric-change {
                    font-size: 0.85rem;
                    font-weight: 600;
                    padding: 4px 12px;
                    border-radius: 20px;
                    display: inline-block;
                    margin-top: 8px;
                }
                
                .positive-change { background: rgba(0, 204, 150, 0.1); color: var(--primary-color); }
                .negative-change { background: rgba(255, 107, 107, 0.1); color: var(--accent-color); }
                
                .table-container {
                    overflow-x: auto;
                    margin-top: 20px;
                }
                
                .data-table {
                    width: 100%;
                    border-collapse: collapse;
                    font-size: 0.95rem;
                }
                
                .data-table th {
                    background: linear-gradient(135deg, var(--dark-bg), #2d3748);
                    color: white;
                    padding: 15px;
                    text-align: left;
                    font-weight: 600;
                }
                
                .data-table td {
                    padding: 15px;
                    border-bottom: 1px solid #eee;
                }
                
                .data-table tr:hover {
                    background: rgba(0, 204, 150, 0.05);
                }
                
                .recommendation-card {
                    background: linear-gradient(135deg, rgba(0, 204, 150, 0.1), rgba(99, 110, 250, 0.1));
                    padding: 25px;
                    border-radius: 12px;
                    margin-top: 20px;
                    border-left: 4px solid var(--primary-color);
                }
                
                .recommendation-title {
                    font-weight: 700;
                    color: var(--dark-bg);
                    margin-bottom: 10px;
                    display: flex;
                    align-items: center;
                    gap: 10px;
                }
                
                .recommendation-content {
                    color: #555;
                    line-height: 1.6;
                }
                
                .footer {
                    text-align: center;
                    padding: 30px;
                    color: #666;
                    font-size: 0.9rem;
                    border-top: 1px solid #eee;
                    margin-top: 40px;
                }
                
                .footer-logo {
                    font-size: 1.5rem;
                    font-weight: 800;
                    color: var(--primary-color);
                    margin-bottom: 10px;
                }
                
                @media print {
                    .report-header { background: white !important; color: black !important; }
                    .report-title { background: none !important; -webkit-text-fill-color: black !important; }
                    .metric-card { break-inside: avoid; }
                    .section { break-inside: avoid; }
                }
            </style>
        </head>
        <body>
            <div class="report-container">
        """
        
        # Header
        html += f"""
                <div class="report-header">
                    <div class="report-title"> QuantEdge Pro Executive Report</div>
                    <div class="report-subtitle">Comprehensive Portfolio Analysis & Insights</div>
                    <div class="report-metadata">
                        <div> Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</div>
                        <div> Report ID: REP_{datetime.now().strftime('%Y%m%d_%H%M%S')}</div>
                        <div> Version: QuantEdge Pro v5.0 Enterprise</div>
                    </div>
                </div>
        """
        
        # Key Metrics Section
        html += """
                <div class="section">
                    <div class="section-title"> Key Performance Metrics</div>
                    <div class="metrics-grid">
        """
        
        # Extract metrics from results
        optimization_results = results.get('optimization_results', {})
        risk_results = results.get('risk_analysis_results', {})
        
        # Define key metrics to display
        key_metrics = [
            ('Expected Return', optimization_results.get('metrics', {}).get('expected_return', 0), 'positive', 'percent'),
            ('Expected Volatility', optimization_results.get('metrics', {}).get('expected_volatility', 0), 'neutral', 'percent'),
            ('Sharpe Ratio', optimization_results.get('metrics', {}).get('sharpe_ratio', 0), 'positive', 'number'),
            ('Max Drawdown', optimization_results.get('metrics', {}).get('max_drawdown', 0), 'negative', 'percent'),
            ('VaR 95%', risk_results.get('methods', {}).get('Historical', {}).get(0.95, {}).get('VaR', 0), 'negative', 'percent'),
            ('CVaR 95%', risk_results.get('methods', {}).get('Historical', {}).get(0.95, {}).get('CVaR', 0), 'negative', 'percent'),
            ('Portfolio Beta', optimization_results.get('metrics', {}).get('beta', 0), 'neutral', 'number'),
            ('Alpha', optimization_results.get('metrics', {}).get('alpha', 0), 'positive', 'percent')
        ]
        
        for label, value, style, fmt in key_metrics:
            if fmt == 'percent':
                display_value = f"{value:.2%}"
            else:
                display_value = f"{value:.3f}"
            
            html += f"""
                        <div class="metric-card">
                            <div class="metric-value {style}">{display_value}</div>
                            <div class="metric-label">{label}</div>
            """
            
            # Add change indicator if available
            if label in ['Expected Return', 'Sharpe Ratio', 'Alpha'] and value > 0:
                html += f'<div class="metric-change positive-change">+{abs(value):.2% if fmt == "percent" else abs(value):.3f}</div>'
            elif label in ['Expected Volatility', 'Max Drawdown', 'VaR 95%', 'CVaR 95%'] and value < 0:
                html += f'<div class="metric-change negative-change">{value:.2% if fmt == "percent" else value:.3f}</div>'
            
            html += "</div>"
        
        html += """
                    </div>
                </div>
        """
        
        # Portfolio Allocation Section
        html += """
                <div class="section">
                    <div class="section-title"> Portfolio Allocation</div>
                    <div class="table-container">
                        <table class="data-table">
                            <thead>
                                <tr>
                                    <th>Asset</th>
                                    <th>Weight</th>
                                    <th>Expected Return</th>
                                    <th>Volatility</th>
                                    <th>Sharpe Ratio</th>
                                </tr>
                            </thead>
                            <tbody>
        """
        
        # Add portfolio assets
        weights = optimization_results.get('weights', {})
        if weights:
            # Calculate individual asset metrics
            portfolio_data = results.get('portfolio_data', {})
            if 'returns' in portfolio_data:
                returns = portfolio_data['returns']
                for ticker, weight in weights.items():
                    if ticker in returns.columns:
                        asset_return = returns[ticker].mean() * 252
                        asset_vol = returns[ticker].std() * np.sqrt(252)
                        asset_sharpe = asset_return / asset_vol if asset_vol > 0 else 0
                        
                        html += f"""
                                <tr>
                                    <td><strong>{ticker}</strong></td>
                                    <td>{weight:.2%}</td>
                                    <td class="{'positive' if asset_return > 0 else 'negative'}">{asset_return:.2%}</td>
                                    <td>{asset_vol:.2%}</td>
                                    <td>{asset_sharpe:.3f}</td>
                                </tr>
                        """
        
        html += """
                            </tbody>
                        </table>
                    </div>
                </div>
        """
        
        # Risk Analysis Section
        html += """
                <div class="section">
                    <div class="section-title"> Risk Analysis Summary</div>
                    <div class="metrics-grid">
        """
        
        # Risk metrics
        risk_metrics = [
            ('VaR Consistency', risk_results.get('summary', {}).get('var_consistency', 0), 'neutral', 'number'),
            ('Liquidity Adjustment', risk_results.get('summary', {}).get('risk_adjustment_factors', {}).get('liquidity_adjustment', 1), 'neutral', 'number'),
            ('Tail Risk Adjustment', risk_results.get('summary', {}).get('risk_adjustment_factors', {}).get('tail_risk_adjustment', 1), 'neutral', 'number'),
            ('Best VaR Method', risk_results.get('summary', {}).get('best_method', 'N/A'), 'neutral', 'text')
        ]
        
        for label, value, style, fmt in risk_metrics:
            if fmt == 'percent':
                display_value = f"{value:.2%}"
            elif fmt == 'number':
                display_value = f"{value:.3f}"
            else:
                display_value = str(value)
            
            html += f"""
                        <div class="metric-card">
                            <div class="metric-value {style}">{display_value}</div>
                            <div class="metric-label">{label}</div>
                        </div>
            """
        
        html += """
                    </div>
                </div>
        """
        
        # Recommendations Section
        html += """
                <div class="section">
                    <div class="section-title"> Key Recommendations</div>
        """
        
        recommendations = [
            "Consider periodic rebalancing to maintain target allocations and manage risk.",
            "Monitor correlation changes between assets to ensure diversification benefits.",
            "Review VaR limits regularly and adjust positions if violations exceed expectations.",
            "Consider incorporating alternative data sources for enhanced predictive analytics.",
            "Implement stress testing as part of regular portfolio review process.",
            "Evaluate the impact of transaction costs on rebalancing decisions."
        ]
        
        for i, recommendation in enumerate(recommendations[:3], 1):
            html += f"""
                    <div class="recommendation-card">
                        <div class="recommendation-title"> Recommendation {i}</div>
                        <div class="recommendation-content">{recommendation}</div>
                    </div>
            """
        
        html += """
                </div>
        """
        
        # Footer
        html += f"""
                <div class="footer">
                    <div class="footer-logo">QUANTEDGE PRO</div>
                    <div>Enterprise Portfolio Analytics Platform | Version 5.0</div>
                    <div> {datetime.now().year} QuantEdge Technologies. All rights reserved.</div>
                    <div style="margin-top: 10px; font-size: 0.8rem; color: #888;">
                        This report is generated automatically and is for informational purposes only.<br>
                        Investment decisions should be based on professional advice and individual circumstances.
                    </div>
                </div>
            </div>
        </body>
        </html>
        """
        
        return html
    
    def _generate_pdf_report(self, results: Dict, report_type: str) -> bytes:
        """Generate PDF report (requires reportlab)."""
        try:
            if not st.session_state.get('reportlab_available', False):
                raise ImportError("ReportLab not available for PDF generation")
            
            from reportlab.lib import colors
            from reportlab.lib.pagesizes import letter, landscape
            from reportlab.platypus import SimpleDocTemplate, Table, TableStyle, Paragraph, Spacer
            from reportlab.lib.styles import getSampleStyleSheet, ParagraphStyle
            from reportlab.lib.units import inch
            from reportlab.pdfgen import canvas
            from io import BytesIO
            
            # Create buffer for PDF
            buffer = BytesIO()
            
            # Create document
            if report_type == 'executive':
                doc = SimpleDocTemplate(buffer, pagesize=letter)
            else:
                doc = SimpleDocTemplate(buffer, pagesize=landscape(letter))
            
            # Styles
            styles = getSampleStyleSheet()
            title_style = ParagraphStyle(
                'CustomTitle',
                parent=styles['Title'],
                fontSize=24,
                textColor=colors.HexColor('#00cc96'),
                spaceAfter=30
            )
            
            heading_style = ParagraphStyle(
                'CustomHeading',
                parent=styles['Heading2'],
                fontSize=16,
                textColor=colors.HexColor('#1a1d2e'),
                spaceAfter=12
            )
            
            # Story elements
            story = []
            
            # Title
            story.append(Paragraph("QuantEdge Pro Portfolio Analysis Report", title_style))
            story.append(Paragraph(f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}", styles['Normal']))
            story.append(Spacer(1, 20))
            
            # Key Metrics Table
            story.append(Paragraph("Key Performance Metrics", heading_style))
            
            # Extract metrics
            optimization_results = results.get('optimization_results', {})
            metrics_data = [
                ['Metric', 'Value'],
                ['Expected Return', f"{optimization_results.get('metrics', {}).get('expected_return', 0):.2%}"],
                ['Expected Volatility', f"{optimization_results.get('metrics', {}).get('expected_volatility', 0):.2%}"],
                ['Sharpe Ratio', f"{optimization_results.get('metrics', {}).get('sharpe_ratio', 0):.3f}"],
                ['Max Drawdown', f"{optimization_results.get('metrics', {}).get('max_drawdown', 0):.2%}"]
            ]
            
            metrics_table = Table(metrics_data)
            metrics_table.setStyle(TableStyle([
                ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#1a1d2e')),
                ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                ('FONTSIZE', (0, 0), (-1, 0), 12),
                ('BOTTOMPADDING', (0, 0), (-1, 0), 12),
                ('BACKGROUND', (0, 1), (-1, -1), colors.HexColor('#f8f9fa')),
                ('GRID', (0, 0), (-1, -1), 1, colors.grey)
            ]))
            
            story.append(metrics_table)
            story.append(Spacer(1, 20))
            
            # Portfolio Allocation Table
            story.append(Paragraph("Portfolio Allocation", heading_style))
            
            weights = optimization_results.get('weights', {})
            if weights:
                allocation_data = [['Asset', 'Weight']]
                for ticker, weight in weights.items():
                    allocation_data.append([ticker, f"{weight:.2%}"])
                
                allocation_table = Table(allocation_data)
                allocation_table.setStyle(TableStyle([
                    ('BACKGROUND', (0, 0), (-1, 0), colors.HexColor('#636efa')),
                    ('TEXTCOLOR', (0, 0), (-1, 0), colors.white),
                    ('ALIGN', (0, 0), (-1, -1), 'CENTER'),
                    ('FONTNAME', (0, 0), (-1, 0), 'Helvetica-Bold'),
                    ('GRID', (0, 0), (-1, -1), 1, colors.grey)
                ]))
                
                story.append(allocation_table)
            
            # Build PDF
            doc.build(story)
            
            # Get PDF bytes
            pdf_bytes = buffer.getvalue()
            buffer.close()
            
            return pdf_bytes
            
        except Exception as e:
            # Return error message as bytes
            return f"PDF Generation Error: {str(e)}".encode()
    
    def _generate_excel_report(self, results: Dict, report_type: str) -> bytes:
        """Generate Excel report."""
        try:
            import io
            import pandas as pd
            from openpyxl import Workbook
            from openpyxl.styles import PatternFill, Font, Alignment, Border, Side
            from openpyxl.utils import get_column_letter
            
            # Create workbook
            wb = Workbook()
            ws = wb.active
            ws.title = "Portfolio Analysis"
            
            # Styles
            header_fill = PatternFill(start_color="1a1d2e", end_color="1a1d2e", fill_type="solid")
            header_font = Font(color="FFFFFF", bold=True)
            metric_fill = PatternFill(start_color="f8f9fa", end_color="f8f9fa", fill_type="solid")
            positive_fill = PatternFill(start_color="d4edda", end_color="d4edda", fill_type="solid")
            negative_fill = PatternFill(start_color="f8d7da", end_color="f8d7da", fill_type="solid")
            center_alignment = Alignment(horizontal="center", vertical="center")
            thin_border = Border(
                left=Side(style='thin'),
                right=Side(style='thin'),
                top=Side(style='thin'),
                bottom=Side(style='thin')
            )
            
            # Header
            ws['A1'] = "QuantEdge Pro Portfolio Analysis Report"
            ws['A1'].font = Font(size=16, bold=True, color="00cc96")
            ws.merge_cells('A1:E1')
            
            ws['A2'] = f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}"
            ws.merge_cells('A2:E2')
            
            # Key Metrics
            ws['A4'] = "Key Performance Metrics"
            ws['A4'].font = Font(size=14, bold=True, color="1a1d2e")
            ws.merge_cells('A4:E4')
            
            optimization_results = results.get('optimization_results', {})
            metrics = [
                ["Metric", "Value"],
                ["Expected Return", optimization_results.get('metrics', {}).get('expected_return', 0)],
                ["Expected Volatility", optimization_results.get('metrics', {}).get('expected_volatility', 0)],
                ["Sharpe Ratio", optimization_results.get('metrics', {}).get('sharpe_ratio', 0)],
                ["Max Drawdown", optimization_results.get('metrics', {}).get('max_drawdown', 0)],
                ["Portfolio Beta", optimization_results.get('metrics', {}).get('beta', 0)],
                ["Alpha", optimization_results.get('metrics', {}).get('alpha', 0)]
            ]
            
            for row_idx, row in enumerate(metrics, start=5):
                for col_idx, value in enumerate(row, start=1):
                    cell = ws.cell(row=row_idx, column=col_idx, value=value)
                    cell.border = thin_border
                    
                    if row_idx == 5:  # Header row
                        cell.fill = header_fill
                        cell.font = header_font
                        cell.alignment = center_alignment
                    else:
                        cell.fill = metric_fill
                        
                        # Format numbers
                        if isinstance(value, float):
                            if row_idx > 5 and col_idx == 2:
                                if "Return" in metrics[row_idx-5][0] or "Alpha" in metrics[row_idx-5][0]:
                                    cell.number_format = '0.00%'
                                    if value > 0:
                                        cell.fill = positive_fill
                                    else:
                                        cell.fill = negative_fill
                                elif "Volatility" in metrics[row_idx-5][0] or "Drawdown" in metrics[row_idx-5][0]:
                                    cell.number_format = '0.00%'
                                else:
                                    cell.number_format = '0.000'
            
            # Portfolio Allocation
            start_row = len(metrics) + 7
            ws.cell(row=start_row, column=1, value="Portfolio Allocation").font = Font(size=14, bold=True)
            ws.merge_cells(f'A{start_row}:E{start_row}')
            
            weights = optimization_results.get('weights', {})
            if weights:
                allocation_header = ["Asset", "Weight", "Expected Return", "Volatility", "Sharpe Ratio"]
                
                for col_idx, header in enumerate(allocation_header, start=1):
                    cell = ws.cell(row=start_row+1, column=col_idx, value=header)
                    cell.fill = header_fill
                    cell.font = header_font
                    cell.alignment = center_alignment
                    cell.border = thin_border
                
                # Get portfolio data for asset-level metrics
                portfolio_data = results.get('portfolio_data', {})
                returns = portfolio_data.get('returns', pd.DataFrame())
                
                for row_idx, (ticker, weight) in enumerate(weights.items(), start=start_row+2):
                    # Asset metrics
                    if ticker in returns.columns:
                        asset_return = returns[ticker].mean() * 252
                        asset_vol = returns[ticker].std() * np.sqrt(252)
                        asset_sharpe = asset_return / asset_vol if asset_vol > 0 else 0
                    else:
                        asset_return = 0
                        asset_vol = 0
                        asset_sharpe = 0
                    
                    row_data = [ticker, weight, asset_return, asset_vol, asset_sharpe]
                    
                    for col_idx, value in enumerate(row_data, start=1):
                        cell = ws.cell(row=row_idx, column=col_idx, value=value)
                        cell.border = thin_border
                        
                        if col_idx == 2:  # Weight column
                            cell.number_format = '0.00%'
                            cell.fill = metric_fill
                        elif col_idx in [3, 4]:  # Return and Volatility columns
                            cell.number_format = '0.00%'
                            if col_idx == 3 and value > 0:
                                cell.fill = positive_fill
                            elif col_idx == 3 and value < 0:
                                cell.fill = negative_fill
                            else:
                                cell.fill = metric_fill
                        elif col_idx == 5:  # Sharpe column
                            cell.number_format = '0.000'
                            cell.fill = metric_fill
            
            # Auto-adjust column widths
            for column in ws.columns:
                max_length = 0
                column_letter = get_column_letter(column[0].column)
                
                for cell in column:
                    try:
                        if len(str(cell.value)) > max_length:
                            max_length = len(str(cell.value))
                    except:
                        pass
                
                adjusted_width = min(max_length + 2, 50)
                ws.column_dimensions[column_letter].width = adjusted_width
            
            # Save to bytes
            output = io.BytesIO()
            wb.save(output)
            output.seek(0)
            
            return output.getvalue()
            
        except Exception as e:
            return f"Excel Generation Error: {str(e)}".encode()
    
    def _generate_executive_text_report(self, results: Dict) -> str:
        """Generate plain text executive report."""
        report = """
        ========================================================================
        QUANTEDGE PRO EXECUTIVE PORTFOLIO ANALYSIS REPORT
        ========================================================================
        
        """
        
        report += f"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n"
        report += f"Report ID: REP_{datetime.now().strftime('%Y%m%d_%H%M%S')}\n"
        report += "Version: QuantEdge Pro v5.0 Enterprise\n\n"
        
        report += "================================================================\n"
        report += " KEY PERFORMANCE METRICS\n"
        report += "================================================================\n\n"
        
        optimization_results = results.get('optimization_results', {})
        metrics = optimization_results.get('metrics', {})
        
        key_metrics = [
            ('Expected Return', metrics.get('expected_return', 0), 'percent'),
            ('Expected Volatility', metrics.get('expected_volatility', 0), 'percent'),
            ('Sharpe Ratio', metrics.get('sharpe_ratio', 0), 'number'),
            ('Max Drawdown', metrics.get('max_drawdown', 0), 'percent'),
            ('Sortino Ratio', metrics.get('sortino_ratio', 0), 'number'),
            ('Calmar Ratio', metrics.get('calmar_ratio', 0), 'number'),
            ('Portfolio Beta', metrics.get('beta', 0), 'number'),
            ('Alpha', metrics.get('alpha', 0), 'percent')
        ]
        
        for label, value, fmt in key_metrics:
            if fmt == 'percent':
                report += f"{label:25} {value:>10.2%}\n"
            else:
                report += f"{label:25} {value:>10.3f}\n"
        
        report += "\n================================================================\n"
        report += " PORTFOLIO ALLOCATION\n"
        report += "================================================================\n\n"
        
        weights = optimization_results.get('weights', {})
        if weights:
            report += "Asset                Weight\n"
            report += "-" * 30 + "\n"
            
            for ticker, weight in sorted(weights.items(), key=lambda x: x[1], reverse=True):
                report += f"{ticker:20} {weight:>8.2%}\n"
        
        report += "\n================================================================\n"
        report += " RISK ASSESSMENT\n"
        report += "================================================================\n\n"
        
        risk_results = results.get('risk_analysis_results', {})
        if risk_results:
            report += "Risk Metric           Value\n"
            report += "-" * 30 + "\n"
            
            risk_metrics = [
                ('VaR 95%', risk_results.get('methods', {}).get('Historical', {}).get(0.95, {}).get('VaR', 0)),
                ('CVaR 95%', risk_results.get('methods', {}).get('Historical', {}).get(0.95, {}).get('CVaR', 0)),
                ('Best Method', risk_results.get('summary', {}).get('best_method', 'N/A'))
            ]
            
            for label, value in risk_metrics:
                if isinstance(value, float):
                    report += f"{label:20} {value:>8.3%}\n"
                else:
                    report += f"{label:20} {value:>8}\n"
        
        report += "\n================================================================\n"
        report += " KEY RECOMMENDATIONS\n"
        report += "================================================================\n\n"
        
        recommendations = [
            "1. Monitor portfolio concentration and consider diversification if any asset exceeds 20%",
            "2. Review risk limits quarterly and adjust as market conditions change",
            "3. Consider implementing stop-loss mechanisms for risk management",
            "4. Evaluate the impact of transaction costs on rebalancing frequency",
            "5. Monitor correlation between assets to ensure diversification benefits",
            "6. Consider stress testing under various market scenarios"
        ]
        
        for rec in recommendations[:4]:
            report += f"{rec}\n"
        
        report += "\n================================================================\n"
        report += "END OF EXECUTIVE REPORT\n"
        report += "================================================================\n"
        report += "Generated by QuantEdge Pro v5.0 Enterprise Edition\n"
        report += " {} QuantEdge Technologies. All rights reserved.\n".format(datetime.now().year)
        
        return report
    
    def _generate_detailed_report(self, results: Dict, format: str) -> Any:
        """Generate detailed technical report."""
        # Implementation similar to executive report but more detailed
        # Would include all backtest results, ML predictions, etc.
        return "Detailed report generation not implemented in this version"
    
    def _generate_regulatory_report(self, results: Dict, format: str) -> Any:
        """Generate regulatory compliance report."""
        # Would include specific regulatory metrics and disclosures
        return "Regulatory report generation not implemented in this version"
    
    def _generate_risk_report(self, results: Dict, format: str) -> Any:
        """Generate detailed risk report."""
        # Focused on risk metrics and analysis
        return "Risk report generation not implemented in this version"
    
    def _generate_error_report(self, error: Exception, format: str) -> Any:
        """Generate error report."""
        error_message = f"""
        ERROR REPORT
        ============
        
        An error occurred during report generation:
        
        Error Type: {type(error).__name__}
        Error Message: {str(error)}
        Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
        
        Please contact support if this error persists.
        """
        
        if format == 'html':
            return f"""
            <html>
            <body style="font-family: Arial, sans-serif; padding: 20px;">
                <h2 style="color: #ef553b;"> Report Generation Error</h2>
                <p><strong>Error Type:</strong> {type(error).__name__}</p>
                <p><strong>Error Message:</strong> {str(error)}</p>
                <p><strong>Timestamp:</strong> {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
                <p>Please contact support if this error persists.</p>
            </body>
            </html>
            """
        else:
            return error_message
    
    def get_report_history(self, limit: int = 10) -> List[Dict]:
        """Get recent report history."""
        return self.report_history[-limit:] if self.report_history else []
    
    def export_report(self, report_id: str, export_format: str = 'file') -> Any:
        """Export report in various formats."""
        # Find the report
        report_record = None
        for report in self.report_history:
            if report['report_id'] == report_id:
                report_record = report
                break
        
        if not report_record:
            return None
        
        # In a real implementation, this would retrieve the actual report content
        # For now, return the record
        return report_record

# Initialize enterprise reporting system
reporting_system = EnterpriseReportingSystem()

# ============================================================================
# 5. ENHANCED MONTE CARLO SIMULATION ENGINE
# ============================================================================

class AdvancedMonteCarloEngine:
    """Advanced Monte Carlo simulation engine with multiple methods."""
    
    def __init__(self):
        self.simulation_results = {}
        self.scenario_analysis = {}
        self.convergence_metrics = {}
        
    def run_comprehensive_monte_carlo(self, returns: pd.DataFrame,
                                    portfolio_weights: Dict,
                                    time_horizon: int = 252,
                                    n_simulations: int = 10000,
                                    simulation_method: str = 'geometric_brownian') -> Dict:
        """Run comprehensive Monte Carlo simulations."""
        try:
            performance_monitor.start_operation('advanced_monte_carlo')
            
            results = {
                'portfolio_simulations': {},
                'asset_simulations': {},
                'risk_metrics': {},
                'scenario_analysis': {},
                'convergence_analysis': {}
            }
            
            # Convert weights to array
            weights_array = np.array(list(portfolio_weights.values()))
            
            # 1. Portfolio-level simulations
            portfolio_sims = self._simulate_portfolio_returns(
                returns, weights_array, time_horizon, n_simulations, simulation_method
            )
            results['portfolio_simulations'] = portfolio_sims
            
            # 2. Asset-level simulations
            asset_sims = self._simulate_individual_assets(
                returns, time_horizon, n_simulations, simulation_method
            )
            results['asset_simulations'] = asset_sims
            
            # 3. Calculate risk metrics
            results['risk_metrics'] = self._calculate_monte_carlo_risk_metrics(portfolio_sims)
            
            # 4. Scenario analysis
            results['scenario_analysis'] = self._analyze_monte_carlo_scenarios(portfolio_sims)
            
            # 5. Convergence analysis
            results['convergence_analysis'] = self._analyze_convergence(portfolio_sims)
            
            performance_monitor.end_operation('advanced_monte_carlo')
            return results
            
        except Exception as e:
            performance_monitor.end_operation('advanced_monte_carlo', {'error': str(e)})
            error_analyzer.analyze_error_with_context(e, {'operation': 'monte_carlo'})
            return self._create_fallback_monte_carlo_results(returns, portfolio_weights, time_horizon)
    
    def _simulate_portfolio_returns(self, returns: pd.DataFrame,
                                  weights: np.ndarray,
                                  time_horizon: int,
                                  n_simulations: int,
                                  method: str) -> Dict:
        """Simulate portfolio returns using specified method."""
        portfolio_returns = returns.dot(weights)
        
        if method == 'geometric_brownian':
            simulations = self._geometric_brownian_motion(portfolio_returns, time_horizon, n_simulations)
        elif method == 'historical_bootstrap':
            simulations = self._historical_bootstrap(portfolio_returns, time_horizon, n_simulations)
        elif method == 'garch':
            simulations = self._garch_monte_carlo(portfolio_returns, time_horizon, n_simulations)
        elif method == 'regime_switching':
            simulations = self._regime_switching_monte_carlo(portfolio_returns, time_horizon, n_simulations)
        else:
            simulations = self._geometric_brownian_motion(portfolio_returns, time_horizon, n_simulations)
        
        # Calculate portfolio values (starting from 1)
        portfolio_values = np.cumprod(1 + simulations, axis=1)
        
        return {
            'simulations': simulations,
            'portfolio_values': portfolio_values,
            'method': method,
            'parameters': {
                'time_horizon': time_horizon,
                'n_simulations': n_simulations,
                'initial_value': 1.0
            }
        }
    
    def _geometric_brownian_motion(self, returns: pd.Series,
                                 time_horizon: int,
                                 n_simulations: int) -> np.ndarray:
        """Simulate using Geometric Brownian Motion."""
        mu = returns.mean() * 252  # Annualized mean
        sigma = returns.std() * np.sqrt(252)  # Annualized volatility
        
        dt = 1/252  # Daily time step
        n_steps = time_horizon
        
        # Random shocks
        shocks = np.random.normal(0, 1, size=(n_simulations, n_steps))
        
        # GBM formula: dS/S = dt + dW
        daily_returns = mu * dt + sigma * np.sqrt(dt) * shocks
        
        return daily_returns
    
    def _historical_bootstrap(self, returns: pd.Series,
                            time_horizon: int,
                            n_simulations: int) -> np.ndarray:
        """Simulate using historical bootstrap method."""
        returns_array = returns.values
        n_historical = len(returns_array)
        
        simulations = np.zeros((n_simulations, time_horizon))
        
        for i in range(n_simulations):
            # Sample with replacement from historical returns
            indices = np.random.choice(n_historical, size=time_horizon, replace=True)
            simulations[i] = returns_array[indices]
        
        return simulations
    
    def _garch_monte_carlo(self, returns: pd.Series,
                         time_horizon: int,
                         n_simulations: int) -> np.ndarray:
        """Simulate using GARCH model (simplified implementation)."""
        try:
            # Simplified GARCH(1,1) simulation
            omega = 0.000001  # Long-run variance
            alpha = 0.1  # ARCH parameter
            beta = 0.85  # GARCH parameter
            
            mu = returns.mean()
            
            simulations = np.zeros((n_simulations, time_horizon))
            
            for i in range(n_simulations):
                # Initialize
                variance = returns.var()
                simulated_returns = np.zeros(time_horizon)
                
                for t in range(time_horizon):
                    # Update variance
                    if t == 0:
                        variance = returns.var()
                    else:
                        variance = omega + alpha * (simulated_returns[t-1] - mu)**2 + beta * variance
                    
                    # Generate return
                    simulated_returns[t] = mu + np.sqrt(variance) * np.random.normal()
                
                simulations[i] = simulated_returns
            
            return simulations
            
        except Exception as e:
            # Fall back to geometric brownian motion
            return self._geometric_brownian_motion(returns, time_horizon, n_simulations)
    
    def _regime_switching_monte_carlo(self, returns: pd.Series,
                                    time_horizon: int,
                                    n_simulations: int) -> np.ndarray:
        """Simulate using regime switching model."""
        try:
            # Simplified two-regime model
            # Regime 1: Normal market
            mu1 = returns.mean()
            sigma1 = returns.std()
            
            # Regime 2: High volatility market
            mu2 = returns.mean() * 0.5  # Lower returns in high vol
            sigma2 = returns.std() * 2.0  # Higher volatility
            
            # Transition probabilities
            p11 = 0.95  # Stay in regime 1
            p12 = 0.05  # Switch from 1 to 2
            p22 = 0.90  # Stay in regime 2
            p21 = 0.10  # Switch from 2 to 1
            
            simulations = np.zeros((n_simulations, time_horizon))
            
            for i in range(n_simulations):
                regime = 1  # Start in normal regime
                simulated_returns = np.zeros(time_horizon)
                
                for t in range(time_horizon):
                    # Generate return based on current regime
                    if regime == 1:
                        simulated_returns[t] = np.random.normal(mu1, sigma1)
                        # Check regime switch
                        if np.random.random() < p12:
                            regime = 2
                    else:
                        simulated_returns[t] = np.random.normal(mu2, sigma2)
                        # Check regime switch
                        if np.random.random() < p21:
                            regime = 1
                
                simulations[i] = simulated_returns
            
            return simulations
            
        except Exception as e:
            return self._geometric_brownian_motion(returns, time_horizon, n_simulations)
    
    def _simulate_individual_assets(self, returns: pd.DataFrame,
                                  time_horizon: int,
                                  n_simulations: int,
                                  method: str) -> Dict:
        """Simulate individual asset returns."""
        asset_simulations = {}
        
        for asset in returns.columns:
            try:
                asset_returns = returns[asset]
                
                if method == 'geometric_brownian':
                    sims = self._geometric_brownian_motion(asset_returns, time_horizon, n_simulations)
                elif method == 'historical_bootstrap':
                    sims = self._historical_bootstrap(asset_returns, time_horizon, n_simulations)
                else:
                    sims = self._geometric_brownian_motion(asset_returns, time_horizon, n_simulations)
                
                asset_simulations[asset] = {
                    'simulations': sims,
                    'asset_values': np.cumprod(1 + sims, axis=1),
                    'method': method
                }
                
            except Exception as e:
                continue
        
        return asset_simulations
    
    def _calculate_monte_carlo_risk_metrics(self, portfolio_sims: Dict) -> Dict:
        """Calculate risk metrics from Monte Carlo simulations."""
        if 'portfolio_values' not in portfolio_sims:
            return {}
        
        portfolio_values = portfolio_sims['portfolio_values']
        n_simulations, n_steps = portfolio_values.shape
        
        # Terminal values
        terminal_values = portfolio_values[:, -1]
        
        # Statistics
        mean_terminal = np.mean(terminal_values)
        median_terminal = np.median(terminal_values)
        std_terminal = np.std(terminal_values)
        
        # Percentiles
        percentiles = {
            'p5': np.percentile(terminal_values, 5),
            'p25': np.percentile(terminal_values, 25),
            'p50': np.percentile(terminal_values, 50),
            'p75': np.percentile(terminal_values, 75),
            'p95': np.percentile(terminal_values, 95)
        }
        
        # Probability of loss
        prob_loss = np.mean(terminal_values < 1.0)  # Below initial investment
        
        # Expected shortfall (CVaR)
        var_95 = np.percentile(terminal_values, 5)
        cvar_95 = terminal_values[terminal_values <= var_95].mean()
        
        # Maximum drawdown distribution
        max_drawdowns = []
        for i in range(n_simulations):
            path = portfolio_values[i]
            cumulative = path
            rolling_max = np.maximum.accumulate(cumulative)
            drawdown = (cumulative - rolling_max) / rolling_max
            max_drawdowns.append(drawdown.min())
        
        avg_max_dd = np.mean(max_drawdowns)
        worst_max_dd = np.min(max_drawdowns)
        
        return {
            'terminal_value': {
                'mean': mean_terminal,
                'median': median_terminal,
                'std': std_terminal,
                'percentiles': percentiles
            },
            'risk_metrics': {
                'probability_loss': prob_loss,
                'var_95': 1 - var_95,  # Convert to loss
                'cvar_95': 1 - cvar_95,
                'expected_max_drawdown': avg_max_dd,
                'worst_max_drawdown': worst_max_dd
            },
            'distribution_stats': {
                'skewness': stats.skew(terminal_values),
                'kurtosis': stats.kurtosis(terminal_values),
                'shapiro_wilk': self._shapiro_wilk_test(terminal_values)
            }
        }
    
    def _shapiro_wilk_test(self, data: np.ndarray, max_samples: int = 5000) -> Dict:
        """Perform Shapiro-Wilk test for normality."""
        try:
            # Limit sample size for performance
            sample_data = data[:min(len(data), max_samples)]
            
            if len(sample_data) < 3:
                return {'statistic': 0, 'p_value': 0, 'is_normal': False}
            
            statistic, p_value = stats.shapiro(sample_data)
            
            return {
                'statistic': statistic,
                'p_value': p_value,
                'is_normal': p_value > 0.05
            }
        except:
            return {'statistic': 0, 'p_value': 0, 'is_normal': False}
    
    def _analyze_monte_carlo_scenarios(self, portfolio_sims: Dict) -> Dict:
        """Analyze different scenarios from Monte Carlo simulations."""
        if 'portfolio_values' not in portfolio_sims:
            return {}
        
        portfolio_values = portfolio_sims['portfolio_values']
        terminal_values = portfolio_values[:, -1]
        
        # Define scenario thresholds
        thresholds = {
            'catastrophic': np.percentile(terminal_values, 1),
            'very_bad': np.percentile(terminal_values, 5),
            'bad': np.percentile(terminal_values, 25),
            'neutral': np.percentile(terminal_values, 50),
            'good': np.percentile(terminal_values, 75),
            'very_good': np.percentile(terminal_values, 95),
            'exceptional': np.percentile(terminal_values, 99)
        }
        
        scenarios = {}
        for scenario_name, threshold in thresholds.items():
            # Find paths that end near this threshold
            mask = np.abs(terminal_values - threshold) < 0.01
            if np.any(mask):
                scenario_paths = portfolio_values[mask]
                avg_path = np.mean(scenario_paths, axis=0)
                
                scenarios[scenario_name] = {
                    'threshold': threshold,
                    'probability': np.mean(mask),
                    'average_path': avg_path,
                    'min_value': np.min(scenario_paths),
                    'max_value': np.max(scenario_paths)
                }
        
        return scenarios
    
    def _analyze_convergence(self, portfolio_sims: Dict) -> Dict:
        """Analyze Monte Carlo convergence."""
        if 'portfolio_values' not in portfolio_sims:
            return {}
        
        portfolio_values = portfolio_sims['portfolio_values']
        terminal_values = portfolio_values[:, -1]
        
        # Check convergence by analyzing stability of mean as simulations increase
        sample_sizes = [100, 500, 1000, 2000, 5000, len(terminal_values)]
        convergence_data = []
        
        for size in sample_sizes:
            if size <= len(terminal_values):
                sample = terminal_values[:size]
                convergence_data.append({
                    'sample_size': size,
                    'mean': np.mean(sample),
                    'std': np.std(sample),
                    'std_error': np.std(sample) / np.sqrt(size)
                })
        
        # Calculate convergence metrics
        if len(convergence_data) > 1:
            final_mean = convergence_data[-1]['mean']
            convergence_errors = [
                abs(data['mean'] - final_mean) / final_mean if final_mean != 0 else 0
                for data in convergence_data
            ]
            
            # Estimate required simulations for desired precision
            desired_precision = 0.01  # 1% precision
            current_std_error = convergence_data[-1]['std_error']
            required_simulations = int((current_std_error / desired_precision) ** 2) if current_std_error > 0 else len(terminal_values)
            
            return {
                'convergence_data': convergence_data,
                'convergence_errors': convergence_errors,
                'is_converged': convergence_errors[-1] < 0.01,  # 1% tolerance
                'required_simulations': min(required_simulations, 100000),
                'current_precision': current_std_error
            }
        
        return {}
    
    def _create_fallback_monte_carlo_results(self, returns: pd.DataFrame,
                                           portfolio_weights: Dict,
                                           time_horizon: int) -> Dict:
        """Create fallback Monte Carlo results."""
        try:
            # Simple geometric brownian motion as fallback
            weights_array = np.array(list(portfolio_weights.values()))
            portfolio_returns = returns.dot(weights_array)
            
            mu = portfolio_returns.mean() * 252
            sigma = portfolio_returns.std() * np.sqrt(252)
            
            n_simulations = 1000
            dt = 1/252
            n_steps = time_horizon
            
            shocks = np.random.normal(0, 1, size=(n_simulations, n_steps))
            daily_returns = mu * dt + sigma * np.sqrt(dt) * shocks
            
            portfolio_values = np.cumprod(1 + daily_returns, axis=1)
            terminal_values = portfolio_values[:, -1]
            
            return {
                'portfolio_simulations': {
                    'simulations': daily_returns,
                    'portfolio_values': portfolio_values,
                    'method': 'fallback_gbm',
                    'parameters': {'time_horizon': time_horizon, 'n_simulations': n_simulations}
                },
                'asset_simulations': {},
                'risk_metrics': {
                    'terminal_value': {
                        'mean': np.mean(terminal_values),
                        'median': np.median(terminal_values),
                        'std': np.std(terminal_values)
                    }
                },
                'scenario_analysis': {},
                'convergence_analysis': {}
            }
        except Exception as e:
            return {
                'portfolio_simulations': {},
                'asset_simulations': {},
                'risk_metrics': {},
                'scenario_analysis': {},
                'convergence_analysis': {}
            }
    
    def generate_monte_carlo_visualizations(self, mc_results: Dict) -> Dict:
        """Generate visualizations for Monte Carlo results."""
        try:
            visualizations = {}
            
            if 'portfolio_simulations' in mc_results:
                portfolio_sims = mc_results['portfolio_simulations']
                
                # 1. Distribution of terminal values
                if 'portfolio_values' in portfolio_sims:
                    terminal_values = portfolio_sims['portfolio_values'][:, -1]
                    
                    fig1 = go.Figure()
                    fig1.add_trace(go.Histogram(
                        x=terminal_values,
                        nbinsx=50,
                        name='Terminal Values',
                        marker_color='#636efa',
                        opacity=0.7
                    ))
                    
                    # Add vertical lines for statistics
                    mean_val = np.mean(terminal_values)
                    median_val = np.median(terminal_values)
                    
                    fig1.add_vline(x=mean_val, line_dash="dash", line_color="green", 
                                 annotation_text=f"Mean: {mean_val:.2f}")
                    fig1.add_vline(x=median_val, line_dash="dash", line_color="blue",
                                 annotation_text=f"Median: {median_val:.2f}")
                    
                    fig1.update_layout(
                        title='Distribution of Terminal Portfolio Values',
                        xaxis_title='Terminal Value',
                        yaxis_title='Frequency',
                        template='plotly_dark',
                        height=500
                    )
                    
                    visualizations['terminal_distribution'] = fig1
                
                # 2. Sample paths visualization
                if 'portfolio_values' in portfolio_sims:
                    portfolio_values = portfolio_sims['portfolio_values']
                    
                    # Select a sample of paths to display
                    n_sample_paths = min(50, portfolio_values.shape[0])
                    sample_indices = np.random.choice(portfolio_values.shape[0], n_sample_paths, replace=False)
                    
                    fig2 = go.Figure()
                    
                    for i, idx in enumerate(sample_indices):
                        fig2.add_trace(go.Scatter(
                            y=portfolio_values[idx],
                            mode='lines',
                            line=dict(width=1, color='rgba(99, 110, 250, 0.3)'),
                            showlegend=False,
                            name=f'Path {i+1}'
                        ))
                    
                    # Add average path
                    avg_path = np.mean(portfolio_values, axis=0)
                    fig2.add_trace(go.Scatter(
                        y=avg_path,
                        mode='lines',
                        line=dict(width=3, color='#00cc96'),
                        name='Average Path'
                    ))
                    
                    # Add confidence bands
                    upper_band = np.percentile(portfolio_values, 95, axis=0)
                    lower_band = np.percentile(portfolio_values, 5, axis=0)
                    
                    fig2.add_trace(go.Scatter(
                        y=upper_band,
                        mode='lines',
                        line=dict(width=0),
                        showlegend=False,
                        name='95th Percentile'
                    ))
                    
                    fig2.add_trace(go.Scatter(
                        y=lower_band,
                        mode='lines',
                        line=dict(width=0),
                        fill='tonexty',
                        fillcolor='rgba(99, 110, 250, 0.2)',
                        showlegend=False,
                        name='5th Percentile'
                    ))
                    
                    fig2.update_layout(
                        title='Monte Carlo Simulation Paths',
                        xaxis_title='Time Steps',
                        yaxis_title='Portfolio Value',
                        template='plotly_dark',
                        height=500,
                        showlegend=True
                    )
                    
                    visualizations['simulation_paths'] = fig2
                
                # 3. Convergence analysis visualization
                if 'convergence_analysis' in mc_results and mc_results['convergence_analysis']:
                    conv_data = mc_results['convergence_analysis'].get('convergence_data', [])
                    
                    if conv_data:
                        sample_sizes = [d['sample_size'] for d in conv_data]
                        means = [d['mean'] for d in conv_data]
                        std_errors = [d['std_error'] for d in conv_data]
                        
                        fig3 = go.Figure()
                        
                        fig3.add_trace(go.Scatter(
                            x=sample_sizes,
                            y=means,
                            mode='lines+markers',
                            name='Mean Estimate',
                            line=dict(color='#00cc96', width=3)
                        ))
                        
                        # Add error bars
                        fig3.add_trace(go.Scatter(
                            x=sample_sizes,
                            y=[m + se for m, se in zip(means, std_errors)],
                            mode='lines',
                            line=dict(width=0),
                            showlegend=False,
                            name='Upper Bound'
                        ))
                        
                        fig3.add_trace(go.Scatter(
                            x=sample_sizes,
                            y=[m - se for m, se in zip(means, std_errors)],
                            mode='lines',
                            line=dict(width=0),
                            fill='tonexty',
                            fillcolor='rgba(0, 204, 150, 0.2)',
                            showlegend=False,
                            name='Lower Bound'
                        ))
                        
                        fig3.update_layout(
                            title='Monte Carlo Convergence Analysis',
                            xaxis_title='Number of Simulations',
                            yaxis_title='Estimated Mean',
                            template='plotly_dark',
                            height=400
                        )
                        
                        visualizations['convergence_analysis'] = fig3
            
            return visualizations
            
        except Exception as e:
            return {}

# Initialize advanced Monte Carlo engine
monte_carlo_engine = AdvancedMonteCarloEngine()

# ============================================================================
# 6. ENHANCED QUANTEDGE PRO ENTERPRISE APPLICATION
# ============================================================================

class QuantEdgeProEnterprise(QuantEdgeProEnhanced):
    """Enterprise edition of QuantEdge Pro with all advanced features."""
    
    def __init__(self):
        super().__init__()
        self.ml_engine = ml_engine
        self.backtesting_engine = backtesting_engine
        self.reporting_system = reporting_system
        self.monte_carlo_engine = monte_carlo_engine
        
        # Initialize enterprise session state
        self._initialize_enterprise_state()
    
    def _initialize_enterprise_state(self):
        """Initialize enterprise-specific session state."""
        enterprise_defaults = {
            'ml_predictions': None,
            'backtest_results': None,
            'monte_carlo_results': None,
            'enterprise_reports': None,
            'alternative_data': None,
            'sentiment_analysis': None,
            'blockchain_data': None,
            'real_time_data': None
        }
        
        for key, value in enterprise_defaults.items():
            if key not in st.session_state:
                st.session_state[key] = value
    
    def render_enterprise_header(self):
        """Render enterprise application header."""
        st.markdown("""
        <style>
            .enterprise-header {
                background: linear-gradient(135deg, 
                    rgba(26, 29, 46, 0.95), 
                    rgba(42, 42, 42, 0.95),
                    rgba(0, 204, 150, 0.1));
                padding: 2.5rem;
                border-radius: 20px;
                margin-bottom: 2.5rem;
                border-left: 8px solid;
                border-image: linear-gradient(135deg, #00cc96, #636efa, #ab63fa) 1;
                box-shadow: 0 20px 50px rgba(0, 0, 0, 0.5);
                text-align: center;
                position: relative;
                overflow: hidden;
            }
            .enterprise-header::before {
                content: '';
                position: absolute;
                top: 0;
                left: 0;
                right: 0;
                bottom: 0;
                background: radial-gradient(circle at 30% 20%, 
                    rgba(0, 204, 150, 0.1) 0%, 
                    transparent 50%),
                    radial-gradient(circle at 70% 80%, 
                    rgba(99, 110, 250, 0.1) 0%, 
                    transparent 50%);
                z-index: -1;
            }
            .enterprise-title {
                background: linear-gradient(135deg, #00cc96, #636efa, #ab63fa, #FF6B6B);
                -webkit-background-clip: text;
                -webkit-text-fill-color: transparent;
                background-clip: text;
                font-size: 4rem;
                font-weight: 900;
                margin-bottom: 1rem;
                letter-spacing: -1px;
                text-shadow: 0 4px 20px rgba(0, 0, 0, 0.3);
            }
            .enterprise-subtitle {
                color: #94a3b8;
                font-size: 1.5rem;
                margin-bottom: 0.8rem;
                font-weight: 400;
            }
            .enterprise-tagline {
                color: #636efa;
                font-size: 1.2rem;
                font-weight: 500;
                background: rgba(99, 110, 250, 0.1);
                display: inline-block;
                padding: 0.5rem 1.5rem;
                border-radius: 30px;
                margin-top: 1rem;
                border: 1px solid rgba(99, 110, 250, 0.3);
            }
            .enterprise-badges {
                display: flex;
                justify-content: center;
                gap: 15px;
                margin-top: 1.5rem;
                flex-wrap: wrap;
            }
            .enterprise-badge {
                background: rgba(255, 255, 255, 0.1);
                padding: 0.5rem 1.2rem;
                border-radius: 20px;
                font-size: 0.9rem;
                font-weight: 600;
                display: flex;
                align-items: center;
                gap: 8px;
                backdrop-filter: blur(10px);
                border: 1px solid rgba(255, 255, 255, 0.1);
            }
            .enterprise-badge.ai { background: linear-gradient(135deg, rgba(0, 204, 150, 0.2), rgba(0, 204, 150, 0.05)); }
            .enterprise-badge.ml { background: linear-gradient(135deg, rgba(99, 110, 250, 0.2), rgba(99, 110, 250, 0.05)); }
            .enterprise-badge.blockchain { background: linear-gradient(135deg, rgba(255, 107, 107, 0.2), rgba(255, 107, 107, 0.05)); }
            .enterprise-badge.realtime { background: linear-gradient(135deg, rgba(171, 99, 250, 0.2), rgba(171, 99, 250, 0.05)); }
        </style>
        
        <div class="enterprise-header">
            <div class="enterprise-title"> QuantEdge Pro v5.0 Enterprise</div>
            <div class="enterprise-subtitle">AI-Powered Institutional Portfolio Analytics Platform</div>
            <div class="enterprise-tagline">Next-Generation Analytics with Machine Learning & Blockchain Integration</div>
            
            <div class="enterprise-badges">
                <div class="enterprise-badge ai"> AI/ML Predictive Analytics</div>
                <div class="enterprise-badge ml"> Advanced Backtesting Engine</div>
                <div class="enterprise-badge blockchain"> Blockchain & Crypto Support</div>
                <div class="enterprise-badge realtime"> Real-time Data Processing</div>
            </div>
        </div>
        """, unsafe_allow_html=True)
        
        # Enterprise feature status
        if ENTERPRISE_LIBRARY_STATUS['enterprise_features']:
            with st.expander(" Enterprise Feature Status", expanded=False):
                col1, col2, col3 = st.columns(3)
                
                features = ENTERPRISE_LIBRARY_STATUS['enterprise_features']
                
                with col1:
                    st.metric(
                        "AI/ML Ready", 
                        "" if features.get('ml_ready', False) else "",
                        delta="Available" if features.get('ml_ready', False) else "Not Available"
                    )
                
                with col2:
                    st.metric(
                        "Alternative Data", 
                        "" if features.get('alternative_data', False) else "",
                        delta="Available" if features.get('alternative_data', False) else "Not Available"
                    )
                
                with col3:
                    st.metric(
                        "Blockchain", 
                        "" if features.get('blockchain', False) else "",
                        delta="Available" if features.get('blockchain', False) else "Not Available"
                    )
    
    def render_enterprise_sidebar(self):
        """Render enterprise sidebar with advanced features."""
        with st.sidebar:
            st.markdown("""
            <div style="
                padding: 1.5rem;
                border-radius: 15px;
                background: linear-gradient(135deg, rgba(30, 30, 30, 0.9), rgba(42, 42, 42, 0.9));
                margin-bottom: 2rem;
                border: 1px solid rgba(255, 255, 255, 0.1);
                box-shadow: 0 8px 32px rgba(0, 0, 0, 0.3);
            ">
                <h3 style="
                    color: #00cc96; 
                    margin-bottom: 1rem; 
                    text-align: center;
                    font-size: 1.5rem;
                    font-weight: 700;
                    display: flex;
                    align-items: center;
                    justify-content: center;
                    gap: 10px;
                ">
                    <span></span> Enterprise Configuration
                </h3>
            </div>
            """, unsafe_allow_html=True)
            
            # Progress tracker
            steps = ['Data Setup', 'ML Analysis', 'Optimization', 'Backtesting', 'Risk Analytics', 'Reports']
            self.ui.create_progress_tracker(steps, st.session_state.current_step)
            
            st.markdown("---")
            
            # Enterprise features section
            st.subheader(" Enterprise Features")
            
            # ML/AI Settings
            with st.expander(" Machine Learning Settings", expanded=False):
                ml_enabled = st.checkbox(
                    "Enable ML Predictive Analytics",
                    value=True,
                    help="Use machine learning for predictions and optimization"
                )
                
                ml_method = st.selectbox(
                    "ML Model Type",
                    ["Ensemble", "Random Forest", "XGBoost", "LSTM"],
                    help="Select machine learning algorithm",
                    disabled=not ml_enabled
                )
                
                prediction_horizon = st.slider(
                    "Prediction Horizon (days)",
                    min_value=5,
                    max_value=60,
                    value=30,
                    step=5,
                    help="Number of days to predict ahead",
                    disabled=not ml_enabled
                )
            
            # Alternative Data Sources
            with st.expander(" Alternative Data", expanded=False):
                use_sentiment = st.checkbox(
                    "News Sentiment Analysis",
                    value=False,
                    help="Incorporate news sentiment in analysis"
                )
                
                use_technical = st.checkbox(
                    "Advanced Technical Indicators",
                    value=True,
                    help="Include advanced technical analysis"
                )
                
                use_blockchain = st.checkbox(
                    "Blockchain Data",
                    value=False,
                    help="Include cryptocurrency and blockchain data",
                    disabled=not ENTERPRISE_LIBRARY_STATUS['enterprise_features'].get('blockchain', False)
                )
            
            # Advanced Backtesting
            with st.expander(" Advanced Backtesting", expanded=False):
                backtest_method = st.selectbox(
                    "Backtesting Method",
                    ["Walk-Forward", "Monte Carlo", "Historical Bootstrap", "Multiple Strategies"],
                    help="Select backtesting methodology"
                )
                
                include_stress_tests = st.checkbox(
                    "Include Stress Testing",
                    value=True,
                    help="Add stress testing scenarios to backtests"
                )
            
            # Report Settings
            with st.expander(" Reporting", expanded=False):
                report_format = st.selectbox(
                    "Report Format",
                    ["HTML", "PDF", "Excel", "Markdown"],
                    help="Select report output format"
                )
                
                report_type = st.selectbox(
                    "Report Type",
                    ["Executive", "Detailed", "Regulatory", "Risk Focused"],
                    help="Select report depth and focus"
                )
            
            st.markdown("---")
            
            # Get base configuration from parent
            base_config, fetch_clicked, run_clicked = super().render_enhanced_sidebar()
            
            # Add enterprise configuration
            if base_config:
                base_config.update({
                    'ml_enabled': ml_enabled,
                    'ml_method': ml_method,
                    'prediction_horizon': prediction_horizon,
                    'use_sentiment': use_sentiment,
                    'use_technical': use_technical,
                    'use_blockchain': use_blockchain,
                    'backtest_method': backtest_method,
                    'include_stress_tests': include_stress_tests,
                    'report_format': report_format.lower(),
                    'report_type': report_type.lower()
                })
            
            # Enterprise action buttons
            st.subheader(" Enterprise Actions")
            
            col1, col2 = st.columns(2)
            
            with col1:
                run_ml_clicked = st.button(
                    " Run ML Analysis",
                    use_container_width=True,
                    key="run_ml_analysis",
                    disabled=not st.session_state.data_fetched,
                    help="Run machine learning predictive analytics"
                )
            
            with col2:
                generate_report_clicked = st.button(
                    " Generate Report",
                    use_container_width=True,
                    key="generate_report",
                    disabled=not st.session_state.analysis_complete,
                    help="Generate comprehensive enterprise report"
                )
            
            # Advanced analytics button
            if st.button(
                " Run Comprehensive Analysis",
                use_container_width=True,
                key="run_comprehensive",
                disabled=not st.session_state.data_fetched,
                type="primary",
                help="Run all analytics including ML, backtesting, and Monte Carlo"
            ):
                st.session_state.current_step = 1
                st.rerun()
            
            return base_config, fetch_clicked, run_clicked, run_ml_clicked, generate_report_clicked
    
    def run_enterprise_analysis(self, config: Dict):
        """Run comprehensive enterprise analysis."""
        try:
            # Update progress
            st.session_state.current_step = 2
            st.session_state.analysis_running = True
            
            # Show progress containers
            progress_bar = st.progress(0, text="Starting enterprise analysis...")
            
            # 1. ML Analysis
            if config.get('ml_enabled', False):
                progress_bar.progress(0.2, text="Running machine learning analysis...")
                ml_results = self.run_ml_analysis(config)
                st.session_state.ml_predictions = ml_results
            
            # 2. Portfolio Optimization (with ML if available)
            progress_bar.progress(0.4, text="Optimizing portfolio...")
            
            if st.session_state.ml_predictions and config.get('ml_enabled', False):
                # Use ML-enhanced optimization
                optimization_results = self.ml_engine.optimize_portfolio_with_ml(
                    st.session_state.portfolio_data['returns_clean'],
                    st.session_state.ml_predictions,
                    config['risk_free_rate']
                )
            else:
                # Use traditional optimization
                optimization_results = self.portfolio_optimizer.optimize_portfolio(
                    returns=st.session_state.portfolio_data['returns_clean'],
                    method=config['optimization_method'],
                    constraints={'bounds': (config['min_weight'], config['max_weight'])},
                    risk_free_rate=config['risk_free_rate']
                )
            
            st.session_state.optimization_results = optimization_results
            
            # 3. Backtesting
            progress_bar.progress(0.6, text="Running backtests...")
            
            # Get benchmark (use first asset as simple benchmark)
            returns = st.session_state.portfolio_data['returns_clean']
            benchmark = returns.iloc[:, 0] if len(returns.columns) > 0 else pd.Series()
            
            backtest_results = self.backtesting_engine.run_comprehensive_backtest(
                returns=returns,
                weights=optimization_results['weights'],
                benchmark_returns=benchmark,
                initial_capital=1000000
            )
            
            st.session_state.backtest_results = backtest_results
            
            # 4. Risk Analysis
            progress_bar.progress(0.8, text="Analyzing risks...")
            
            # Calculate portfolio returns
            weights_array = np.array(list(optimization_results['weights'].values()))
            portfolio_returns = returns.dot(weights_array)
            
            risk_analysis_results = self.risk_analytics.calculate_comprehensive_var_analysis(
                portfolio_returns,
                portfolio_value=1000000
            )
            
            st.session_state.risk_analysis_results = risk_analysis_results
            
            # 5. Monte Carlo Simulations
            progress_bar.progress(0.9, text="Running Monte Carlo simulations...")
            
            monte_carlo_results = self.monte_carlo_engine.run_comprehensive_monte_carlo(
                returns=returns,
                portfolio_weights=optimization_results['weights'],
                time_horizon=252,  # 1 year
                n_simulations=5000,
                simulation_method='geometric_brownian'
            )
            
            st.session_state.monte_carlo_results = monte_carlo_results
            
            # Complete
            progress_bar.progress(1.0, text="Analysis complete!")
            
            st.session_state.current_step = 5
            st.session_state.analysis_complete = True
            st.session_state.analysis_running = False
            
            time.sleep(0.5)
            progress_bar.empty()
            
            st.success(" Enterprise analysis complete!")
            
            # Show quick summary
            self._display_enterprise_summary()
            
            return True
            
        except Exception as e:
            st.session_state.analysis_running = False
            progress_bar.empty()
            
            error_analysis = error_analyzer.analyze_error_with_context(e, {
                'operation': 'enterprise_analysis',
                'ml_enabled': config.get('ml_enabled', False)
            })
            
            st.error(f" Error during enterprise analysis: {str(e)}")
            
            with st.expander("Error Details", expanded=False):
                error_analyzer.create_advanced_error_display(error_analysis)
            
            return False
    
    def run_ml_analysis(self, config: Dict):
        """Run machine learning analysis."""
        try:
            if st.session_state.portfolio_data is None:
                st.error("Please fetch data first")
                return None
            
            with st.spinner(" Running machine learning analysis..."):
                # Prepare data
                returns = st.session_state.portfolio_data['returns_clean']
                prices = st.session_state.portfolio_data['prices_clean']
                
                # Train prediction model
                ml_results = self.ml_engine.train_price_prediction_model(
                    prices=prices,
                    horizon=config.get('prediction_horizon', 30),
                    model_type=config.get('ml_method', 'ensemble').lower()
                )
                
                # Generate predictions
                predictions = self.ml_engine.predict_portfolio_returns(
                    portfolio_data=st.session_state.portfolio_data,
                    model_results=ml_results,
                    forecast_periods=config.get('prediction_horizon', 30)
                )
                
                # Sentiment analysis (if enabled)
                if config.get('use_sentiment', False):
                    sentiment_results = self.ml_engine.analyze_sentiment_impact(
                        tickers=list(returns.columns)
                    )
                    ml_results['sentiment_analysis'] = sentiment_results
                
                ml_results['predictions'] = predictions
                
                return ml_results
                
        except Exception as e:
            error_analyzer.analyze_error_with_context(e, {'operation': 'ml_analysis'})
            st.warning(f"ML analysis failed: {str(e)}. Using traditional methods.")
            return None
    
    def _display_enterprise_summary(self):
        """Display enterprise analysis summary."""
        with st.expander(" Enterprise Analysis Summary", expanded=True):
            col1, col2, col3, col4 = st.columns(4)
            
            # ML Metrics
            with col1:
                if st.session_state.ml_predictions:
                    ml_performance = st.session_state.ml_predictions.get('performance', {})
                    st.metric(
                        "ML Model R",
                        f"{ml_performance.get('r2', 0):.3f}",
                        delta="Good" if ml_performance.get('r2', 0) > 0.5 else "Poor"
                    )
            
            # Optimization Metrics
            with col2:
                if st.session_state.optimization_results:
                    metrics = st.session_state.optimization_results['metrics']
                    st.metric(
                        "Sharpe Ratio",
                        f"{metrics.get('sharpe_ratio', 0):.3f}",
                        delta="Good" if metrics.get('sharpe_ratio', 0) > 1.0 else "Needs Improvement"
                    )
            
            # Backtesting Metrics
            with col3:
                if st.session_state.backtest_results:
                    backtest_metrics = st.session_state.backtest_results.get('performance_metrics', {})
                    st.metric(
                        "Backtest Return",
                        f"{backtest_metrics.get('annual_return', 0):.2%}",
                        delta="Positive" if backtest_metrics.get('annual_return', 0) > 0 else "Negative"
                    )
            
            # Risk Metrics
            with col4:
                if st.session_state.risk_analysis_results:
                    risk_summary = st.session_state.risk_analysis_results.get('summary', {})
                    st.metric(
                        "Risk Score",
                        f"{risk_summary.get('var_consistency', 0):.3f}",
                        delta="Stable" if risk_summary.get('var_consistency', 0) < 0.1 else "Volatile"
                    )
    
    def render_enterprise_results(self):
        """Render enterprise analysis results."""
        if not st.session_state.analysis_complete:
            return
        
        # Create main tabs for enterprise features
        tab1, tab2, tab3, tab4, tab5, tab6 = st.tabs([
            " ML Analytics",
            " Portfolio Optimization",
            " Backtesting",
            " Risk Analysis",
            " Monte Carlo",
            " Reports"
        ])
        
        with tab1:
            self.render_ml_analytics()
        
        with tab2:
            self.render_optimization_results()
        
        with tab3:
            self.render_backtesting_results()
        
        with tab4:
            self.render_risk_analysis_results()
        
        with tab5:
            self.render_monte_carlo_results()
        
        with tab6:
            self.render_enterprise_reports()
    
    def render_ml_analytics(self):
        """Render machine learning analytics results."""
        if st.session_state.ml_predictions is None:
            st.info("No ML analysis results available. Enable ML analysis in settings.")
            return
        
        ml_results = st.session_state.ml_predictions
        
        st.markdown('<h2 class="section-header"> Machine Learning Analytics</h2>', 
                   unsafe_allow_html=True)
        
        # Model Performance
        st.subheader(" Model Performance")
        
        if 'performance' in ml_results:
            perf = ml_results['performance']
            
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("R Score", f"{perf.get('r2', 0):.3f}")
            with col2:
                st.metric("MSE", f"{perf.get('mse', 0):.6f}")
            with col3:
                st.metric("RMSE", f"{perf.get('rmse', 0):.4f}")
            with col4:
                st.metric("Model Type", perf.get('model_type', 'Unknown'))
        
        # Predictions
        st.subheader(" Predictions")
        
        if 'predictions' in ml_results:
            predictions = ml_results['predictions']
            
            if 'expected_returns' in predictions:
                expected_returns = predictions['expected_returns']
                
                # Display as dataframe
                if isinstance(expected_returns, dict):
                    df_predictions = pd.DataFrame.from_dict(
                        expected_returns, 
                        orient='index', 
                        columns=['Expected Return']
                    )
                    st.dataframe(df_predictions.style.format({'Expected Return': '{:.2%}'}))
            
            # Confidence intervals
            if 'confidence_intervals' in predictions:
                conf = predictions['confidence_intervals']
                
                col1, col2 = st.columns(2)
                with col1:
                    st.metric("95% CI Lower", f"{conf.get('percentile_5', 0):.3%}")
                with col2:
                    st.metric("95% CI Upper", f"{conf.get('percentile_95', 0):.3%}")
        
        # Feature Importance
        if 'feature_importance' in ml_results and ml_results['feature_importance']:
            st.subheader(" Feature Importance")
            
            importance_df = pd.DataFrame.from_dict(
                ml_results['feature_importance'],
                orient='index',
                columns=['Importance']
            ).sort_values('Importance', ascending=False)
            
            # Display top 10 features
            top_features = importance_df.head(10)
            
            fig = px.bar(
                top_features,
                x=top_features.index,
                y='Importance',
                title='Top 10 Most Important Features',
                color='Importance',
                color_continuous_scale='Viridis'
            )
            fig.update_layout(template='plotly_dark')
            st.plotly_chart(fig, use_container_width=True)
        
        # Sentiment Analysis
        if 'sentiment_analysis' in ml_results:
            st.subheader(" Sentiment Analysis")
            
            sentiment = ml_results['sentiment_analysis']
            
            if 'sentiment_scores' in sentiment:
                scores = sentiment['sentiment_scores']
                
                # Create sentiment gauge
                avg_sentiment = np.mean(list(scores.values())) if scores else 0
                
                fig = go.Figure(go.Indicator(
                    mode="gauge+number",
                    value=avg_sentiment,
                    title={'text': "Average Sentiment"},
                    gauge={
                        'axis': {'range': [-1, 1]},
                        'bar': {'color': "white"},
                        'steps': [
                            {'range': [-1, -0.3], 'color': "#ef553b"},
                            {'range': [-0.3, 0.3], 'color': "#FFA15A"},
                            {'range': [0.3, 1], 'color': "#00cc96"}
                        ]
                    }
                ))
                fig.update_layout(template='plotly_dark', height=300)
                st.plotly_chart(fig, use_container_width=True)
            
            # Recommendations
            if 'recommendations' in sentiment and sentiment['recommendations']:
                st.subheader(" Sentiment-based Recommendations")
                
                for rec in sentiment['recommendations'][:3]:
                    st.info(rec)
    
    def render_backtesting_results(self):
        """Render backtesting results."""
        if st.session_state.backtest_results is None:
            st.info("No backtesting results available.")
            return
        
        backtest_results = st.session_state.backtest_results
        
        st.markdown('<h2 class="section-header"> Advanced Backtesting Results</h2>', 
                   unsafe_allow_html=True)
        
        # Performance Metrics
        st.subheader(" Backtest Performance")
        
        if 'performance_metrics' in backtest_results:
            perf = backtest_results['performance_metrics']
            
            cols = st.columns(4)
            metrics = [
                ('Total Return', 'total_return'),
                ('Annual Return', 'annual_return'),
                ('Sharpe Ratio', 'sharpe_ratio'),
                ('Max Drawdown', 'max_drawdown')
            ]
            
            for (label, key), col in zip(metrics, cols):
                if key in perf:
                    value = perf[key]
                    delta = None
                    if key == 'sharpe_ratio':
                        delta = "Good" if value > 1.0 else "Needs Improvement"
                    elif key == 'max_drawdown':
                        delta = "Severe" if value < -0.2 else "Moderate"
                    
                    col.metric(label, 
                              f"{value:.2%}" if 'return' in key or 'drawdown' in key else f"{value:.3f}",
                              delta=delta)
        
        # Strategy Comparison
        st.subheader(" Strategy Comparison")
        
        if 'strategy_comparison' in backtest_results:
            strategies = backtest_results['strategy_comparison']
            
            # Create comparison table
            comparison_data = []
            for strategy_name, strategy_metrics in strategies.items():
                comparison_data.append({
                    'Strategy': strategy_name.replace('_', ' ').title(),
                    'Annual Return': strategy_metrics.get('annual_return', 0),
                    'Sharpe Ratio': strategy_metrics.get('sharpe_ratio', 0),
                    'Max Drawdown': strategy_metrics.get('max_drawdown', 0),
                    'Win Rate': strategy_metrics.get('win_rate', 0)
                })
            
            if comparison_data:
                df_comparison = pd.DataFrame(comparison_data)
                
                # Format percentages
                styled_df = df_comparison.style.format({
                    'Annual Return': '{:.2%}',
                    'Max Drawdown': '{:.2%}',
                    'Win Rate': '{:.1%}',
                    'Sharpe Ratio': '{:.3f}'
                })
                
                st.dataframe(styled_df, use_container_width=True)
        
        # Portfolio Evolution Chart
        if 'portfolio_evolution' in backtest_results:
            st.subheader(" Portfolio Evolution")
            
            portfolio_values = backtest_results['portfolio_evolution']
            
            if not portfolio_values.empty:
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=portfolio_values.index,
                    y=portfolio_values.values,
                    mode='lines',
                    name='Portfolio Value',
                    line=dict(color='#00cc96', width=3)
                ))
                
                fig.update_layout(
                    title='Portfolio Value Over Time',
                    xaxis_title='Date',
                    yaxis_title='Portfolio Value ($)',
                    template='plotly_dark',
                    height=500
                )
                
                st.plotly_chart(fig, use_container_width=True)
        
        # Risk Analysis
        if 'risk_analysis' in backtest_results:
            st.subheader(" Backtest Risk Analysis")
            
            risk = backtest_results['risk_analysis']
            
            cols = st.columns(3)
            risk_metrics = [
                ('VaR 95%', 'var_95'),
                ('CVaR 95%', 'cvar_95'),
                ('Tail Risk Ratio', 'tail_risk_ratio')
            ]
            
            for (label, key), col in zip(risk_metrics, cols):
                if key in risk:
                    col.metric(label, f"{risk[key]:.3%}" if key != 'tail_risk_ratio' else f"{risk[key]:.3f}")
    
    def render_monte_carlo_results(self):
        """Render Monte Carlo simulation results."""
        if st.session_state.monte_carlo_results is None:
            st.info("No Monte Carlo simulation results available.")
            return
        
        mc_results = st.session_state.monte_carlo_results
        
        st.markdown('<h2 class="section-header"> Monte Carlo Simulation Analysis</h2>', 
                   unsafe_allow_html=True)
        
        # Risk Metrics from Monte Carlo
        st.subheader(" Simulation Risk Metrics")
        
        if 'risk_metrics' in mc_results:
            risk = mc_results['risk_metrics']
            
            if 'terminal_value' in risk:
                term = risk['terminal_value']
                
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("Mean Terminal Value", f"{term.get('mean', 0):.3f}")
                with col2:
                    st.metric("Median Terminal Value", f"{term.get('median', 0):.3f}")
                with col3:
                    st.metric("Std Terminal Value", f"{term.get('std', 0):.3f}")
                with col4:
                    st.metric("Probability of Loss", 
                             f"{risk.get('risk_metrics', {}).get('probability_loss', 0):.2%}")
            
            # Percentiles
            if 'percentiles' in risk.get('terminal_value', {}):
                percentiles = risk['terminal_value']['percentiles']
                
                st.subheader(" Terminal Value Distribution")
                
                cols = st.columns(5)
                percentile_labels = [
                    ('5th Percentile', 'p5'),
                    ('25th Percentile', 'p25'),
                    ('50th Percentile', 'p50'),
                    ('75th Percentile', 'p75'),
                    ('95th Percentile', 'p95')
                ]
                
                for (label, key), col in zip(percentile_labels, cols):
                    if key in percentiles:
                        col.metric(label, f"{percentiles[key]:.3f}")
        
        # Visualizations
        st.subheader(" Simulation Visualizations")
        
        visualizations = self.monte_carlo_engine.generate_monte_carlo_visualizations(mc_results)
        
        for viz_name, figure in visualizations.items():
            st.plotly_chart(figure, use_container_width=True)
        
        # Scenario Analysis
        if 'scenario_analysis' in mc_results:
            scenarios = mc_results['scenario_analysis']
            
            if scenarios:
                st.subheader(" Scenario Analysis")
                
                # Create scenario comparison
                scenario_data = []
                for scenario_name, scenario_info in scenarios.items():
                    scenario_data.append({
                        'Scenario': scenario_name.replace('_', ' ').title(),
                        'Terminal Value': scenario_info.get('threshold', 0),
                        'Probability': scenario_info.get('probability', 0),
                        'Min Value': scenario_info.get('min_value', 0),
                        'Max Value': scenario_info.get('max_value', 0)
                    })
                
                if scenario_data:
                    df_scenarios = pd.DataFrame(scenario_data)
                    styled_df = df_scenarios.style.format({
                        'Terminal Value': '{:.3f}',
                        'Probability': '{:.2%}',
                        'Min Value': '{:.3f}',
                        'Max Value': '{:.3f}'
                    })
                    
                    st.dataframe(styled_df, use_container_width=True)
    
    def render_enterprise_reports(self):
        """Render enterprise reporting interface."""
        st.markdown('<h2 class="section-header"> Enterprise Reporting</h2>', 
                   unsafe_allow_html=True)
        
        # Report generation interface
        col1, col2, col3 = st.columns(3)
        
        with col1:
            report_type = st.selectbox(
                "Report Type",
                ["Executive", "Detailed", "Risk Focused", "Regulatory"],
                key="report_type_select"
            )
        
        with col2:
            report_format = st.selectbox(
                "Output Format",
                ["HTML", "PDF", "Excel", "Text"],
                key="report_format_select"
            )
        
        with col3:
            include_ml = st.checkbox("Include ML Analysis", value=True)
            include_backtest = st.checkbox("Include Backtesting", value=True)
            include_monte_carlo = st.checkbox("Include Monte Carlo", value=True)
        
        # Generate report button
        if st.button(" Generate Comprehensive Report", use_container_width=True, type="primary"):
            with st.spinner(f"Generating {report_type} report in {report_format} format..."):
                # Prepare analysis results
                analysis_results = {
                    'optimization_results': st.session_state.optimization_results,
                    'risk_analysis_results': st.session_state.risk_analysis_results,
                    'portfolio_data': st.session_state.portfolio_data,
                    'config': st.session_state.config
                }
                
                if include_ml and st.session_state.ml_predictions:
                    analysis_results['ml_predictions'] = st.session_state.ml_predictions
                
                if include_backtest and st.session_state.backtest_results:
                    analysis_results['backtest_results'] = st.session_state.backtest_results
                
                if include_monte_carlo and st.session_state.monte_carlo_results:
                    analysis_results['monte_carlo_results'] = st.session_state.monte_carlo_results
                
                # Generate report
                report = self.reporting_system.generate_comprehensive_report(
                    analysis_results=analysis_results,
                    report_type=report_type.lower(),
                    format=report_format.lower()
                )
                
                if report and 'content' in report:
                    st.success(f" Report generated successfully! Report ID: {report.get('report_id', 'N/A')}")
                    
                    # Display or download report based on format
                    if report_format.lower() == 'html':
                        with st.expander(" View Report", expanded=True):
                            st.components.v1.html(report['content'], height=800, scrolling=True)
                    
                    elif report_format.lower() == 'text':
                        with st.expander(" View Report", expanded=True):
                            st.text(report['content'])
                    
                    # Download button
                    st.download_button(
                        label=" Download Report",
                        data=report['content'] if isinstance(report['content'], (str, bytes)) else str(report['content']),
                        file_name=f"quantedge_report_{report['report_id']}.{report_format.lower()}",
                        mime={
                            'html': 'text/html',
                            'pdf': 'application/pdf',
                            'excel': 'application/vnd.openxmlformats-officedocument.spreadsheetml.sheet',
                            'text': 'text/plain'
                        }.get(report_format.lower(), 'text/plain'),
                        use_container_width=True
                    )
        
        # Report history
        st.subheader(" Report History")
        
        report_history = self.reporting_system.get_report_history(limit=10)
        
        if report_history:
            for report in report_history:
                with st.expander(f"Report: {report['report_id']} ({report['timestamp']})", expanded=False):
                    col1, col2 = st.columns(2)
                    with col1:
                        st.write(f"**Type:** {report['type']}")
                        st.write(f"**Format:** {report['format']}")
                    with col2:
                        st.write(f"**Size:** {report['size']} bytes")
                        st.write(f"**Generated:** {report['timestamp']}")
        else:
            st.info("No reports generated yet.")
    
    def run_enterprise(self):
        """Main enterprise application runner."""
        try:
            # Set enterprise CSS
            st.markdown("""
            <style>
                .stApp {
                    background: linear-gradient(135deg, 
                        #0e1117 0%, 
                        #1a1d2e 30%, 
                        #2d1b2e 70%, 
                        #0e1117 100%);
                }
                .enterprise-section {
                    background: linear-gradient(135deg, 
                        rgba(26, 29, 46, 0.8), 
                        rgba(42, 42, 42, 0.8));
                    border-radius: 20px;
                    padding: 2rem;
                    margin: 2rem 0;
                    border: 1px solid rgba(255, 255, 255, 0.1);
                    box-shadow: 0 20px 50px rgba(0, 0, 0, 0.3);
                }
                .enterprise-card {
                    background: rgba(30, 30, 30, 0.6);
                    border-radius: 15px;
                    padding: 1.5rem;
                    border: 1px solid rgba(255, 255, 255, 0.05);
                    transition: all 0.3s ease;
                    height: 100%;
                }
                .enterprise-card:hover {
                    border-color: rgba(0, 204, 150, 0.3);
                    box-shadow: 0 10px 30px rgba(0, 204, 150, 0.1);
                    transform: translateY(-5px);
                }
                .enterprise-metric {
                    font-size: 2.5rem;
                    font-weight: 800;
                    background: linear-gradient(135deg, #00cc96, #636efa);
                    -webkit-background-clip: text;
                    -webkit-text-fill-color: transparent;
                    background-clip: text;
                    margin: 1rem 0;
                }
                .feature-grid {
                    display: grid;
                    grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
                    gap: 20px;
                    margin: 2rem 0;
                }
            </style>
            """, unsafe_allow_html=True)
            
            # Render enterprise header
            self.render_enterprise_header()
            
            # Render sidebar and get configuration
            config, fetch_clicked, run_clicked, run_ml_clicked, generate_report_clicked = self.render_enterprise_sidebar()
            
            # Handle data fetching
            if fetch_clicked:
                success = self.run_data_fetch(config)
                if success:
                    st.rerun()
            
            # Handle ML analysis
            if run_ml_clicked and st.session_state.data_fetched:
                with st.spinner("Running machine learning analysis..."):
                    ml_results = self.run_ml_analysis(config)
                    if ml_results:
                        st.session_state.ml_predictions = ml_results
                        st.success(" ML analysis complete!")
                        st.rerun()
            
            # Handle comprehensive analysis
            if run_clicked and st.session_state.data_fetched:
                success = self.run_enterprise_analysis(config)
                if success:
                    st.rerun()
            
            # Handle report generation
            if generate_report_clicked and st.session_state.analysis_complete:
                # This is handled in the render_enterprise_reports method
                pass
            
            # Show data status
            if st.session_state.data_fetched and not st.session_state.analysis_complete:
                st.info("""
                ###  Data Ready for Analysis
                
                Your data has been successfully fetched and is ready for analysis. 
                
                **Available Actions:**
                1. **Run ML Analysis** - Train machine learning models and generate predictions
                2. **Run Comprehensive Analysis** - Full analysis including optimization, backtesting, and risk analysis
                3. **Generate Report** - Create professional reports (requires analysis completion)
                """)
                
                # Quick data preview
                with st.expander(" Quick Data Preview", expanded=False):
                    if st.session_state.portfolio_data:
                        returns = st.session_state.portfolio_data.get('returns_clean', 
                                                                    st.session_state.portfolio_data.get('returns', pd.DataFrame()))
                        if not returns.empty:
                            st.write(f"**Assets:** {len(returns.columns)}")
                            st.write(f"**Time Period:** {len(returns)} trading days")
                            st.write(f"**Date Range:** {returns.index[0].date()} to {returns.index[-1].date()}")
            
            # Render results if analysis is complete
            if st.session_state.analysis_complete:
                self.render_enterprise_results()
            
            # Show analysis running status
            if st.session_state.analysis_running:
                st.info("""
                ###  Enterprise Analysis in Progress
                
                The system is currently running comprehensive analysis including:
                -  Machine Learning Predictions
                -  Portfolio Optimization
                -  Advanced Backtesting
                -  Risk Analysis
                -  Monte Carlo Simulations
                
                This may take a few minutes depending on data size and complexity.
                """)
            
            # Enterprise footer
            st.markdown("---")
            st.markdown("""
            <div style="
                text-align: center; 
                color: #94a3b8; 
                font-size: 0.9rem; 
                padding: 2rem 0;
                background: rgba(26, 29, 46, 0.5);
                border-radius: 15px;
                margin-top: 3rem;
            ">
                <p style="font-size: 1.2rem; margin-bottom: 1rem;">
                    <strong style="
                        background: linear-gradient(135deg, #00cc96, #636efa);
                        -webkit-background-clip: text;
                        -webkit-text-fill-color: transparent;
                        background-clip: text;
                    "> QuantEdge Pro v5.0 Enterprise Edition</strong>
                </p>
                <p>AI-Powered Portfolio Analytics Platform  5500+ Lines of Production Code</p>
                <p>Enterprise Features: Machine Learning  Advanced Backtesting  Real-time Analytics  Blockchain Integration</p>
                <p style="margin-top: 1.5rem; font-size: 0.8rem; color: #636efa;">
                     {} QuantEdge Technologies. Enterprise License. All rights reserved.<br>
                    For Institutional Use Only. Not for Retail Distribution.
                </p>
            </div>
            """.format(datetime.now().year), unsafe_allow_html=True)
            
            # Performance monitor button
            with st.sidebar:
                if st.button(" Performance Dashboard", use_container_width=True, key="enterprise_perf_dashboard"):
                    report = performance_monitor.get_performance_report()
                    
                    with st.expander("Performance Dashboard", expanded=True):
                        st.subheader(" System Performance")
                        
                        # Key metrics
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("Total Runtime", f"{report.get('total_runtime', 0):.1f}s")
                        with col2:
                            st.metric("Operations", report.get('summary', {}).get('total_operations', 0))
                        with col3:
                            st.metric("Memory Usage", "Monitoring")
                        
                        # Recommendations
                        if report.get('recommendations'):
                            st.subheader(" Optimization Recommendations")
                            for rec in report['recommendations'][:3]:
                                st.info(rec)
                        
                        # Operation details
                        st.subheader(" Operation Details")
                        for op_name, op_stats in report.get('operations', {}).items():
                            with st.expander(f"{op_name} ({op_stats.get('count', 0)} runs)", expanded=False):
                                col1, col2 = st.columns(2)
                                with col1:
                                    st.metric("Avg Duration", f"{op_stats.get('avg_duration', 0):.2f}s")
                                with col2:
                                    st.metric("Avg Memory", f"{op_stats.get('avg_memory_increase', 0):.1f}MB")
            
        except Exception as e:
            # Global error handling for enterprise edition
            error_analysis = error_analyzer.analyze_error_with_context(e, {
                'operation': 'enterprise_application_runtime',
                'stage': 'enterprise_main',
                'version': '5.0'
            })
            
            st.error("""
            ##  Enterprise Application Error
            
            The enterprise application encountered a critical error. 
            
            **Recommended Actions:**
            1. Check your internet connection and data sources
            2. Reduce the number of assets or time period
            3. Ensure all required libraries are installed
            4. Check system resources (memory, CPU)
            
            **Technical Support:**
            - Error ID: {error_id}
            - Timestamp: {timestamp}
            - Version: QuantEdge Pro v5.0 Enterprise
            
            Please contact enterprise support with the error details below.
            """.format(
                error_id=hashlib.md5(str(e).encode()).hexdigest()[:8],
                timestamp=datetime.now().strftime('%Y-%m-%d %H:%M:%S')
            ))
            
            with st.expander(" Technical Error Details", expanded=False):
                error_analyzer.create_advanced_error_display(error_analysis)
                
                # Additional debugging info
                st.subheader(" System Information")
                col1, col2 = st.columns(2)
                with col1:
                    st.write(f"Python Version: {sys.version}")
                    st.write(f"Streamlit Version: {st.__version__}")
                with col2:
                    st.write(f"Pandas Version: {pd.__version__}")
                    st.write(f"Numpy Version: {np.__version__}")

# ============================================================================
# 7. ENTERPRISE MAIN EXECUTION
# ============================================================================

def enterprise_main():
    """Main entry point for the enterprise edition."""
    try:
        # Set page configuration for enterprise
        st.set_page_config(
            page_title="QuantEdge Pro v5.0 Enterprise",
            page_icon="",
            layout="wide",
            initial_sidebar_state="expanded",
            menu_items={
                'Get Help': 'https://quantedge.com/enterprise-support',
                'Report a bug': 'https://quantedge.com/enterprise-bug-report',
                'About': '''
                # QuantEdge Pro v5.0 Enterprise
                
                Advanced Portfolio Analytics Platform with AI/ML Integration
                
                **Features:**
                - Machine Learning Predictive Analytics
                - Advanced Backtesting Engine
                - Comprehensive Risk Analysis
                - Monte Carlo Simulations
                - Enterprise Reporting System
                - Blockchain & Alternative Data Support
                
                **License:** Enterprise Edition
                **Version:** 5.0.0
                ** 2024 QuantEdge Technologies**
                '''
            }
        )
        
        # Custom CSS for enterprise
        st.markdown("""
        <style>
            /* Hide Streamlit branding */
            #MainMenu {visibility: hidden;}
            footer {visibility: hidden;}
            header {visibility: hidden;}
            .stDeployButton {display: none !important;}
            
            /* Custom scrollbar */
            ::-webkit-scrollbar {
                width: 10px;
                height: 10px;
            }
            ::-webkit-scrollbar-track {
                background: rgba(255, 255, 255, 0.05);
                border-radius: 10px;
            }
            ::-webkit-scrollbar-thumb {
                background: linear-gradient(135deg, #00cc96, #636efa);
                border-radius: 10px;
            }
            ::-webkit-scrollbar-thumb:hover {
                background: linear-gradient(135deg, #00cc96, #ab63fa);
            }
            
            /* Better data table styling */
            .dataframe {
                border-radius: 10px;
                overflow: hidden;
                border: 1px solid rgba(255, 255, 255, 0.1);
            }
            .dataframe th {
                background: linear-gradient(135deg, #1a1d2e, #2d3748) !important;
                color: white !important;
                font-weight: 600 !important;
            }
            .dataframe tr:hover {
                background: rgba(0, 204, 150, 0.1) !important;
            }
            
            /* Metric cards enhancement */
            [data-testid="stMetric"] {
                background: rgba(30, 30, 30, 0.6);
                padding: 1rem;
                border-radius: 10px;
                border: 1px solid rgba(255, 255, 255, 0.05);
            }
            [data-testid="stMetric"]:hover {
                border-color: rgba(0, 204, 150, 0.3);
                box-shadow: 0 5px 20px rgba(0, 204, 150, 0.1);
            }
            
            /* Button enhancements */
            .stButton > button {
                background: linear-gradient(135deg, #00cc96, #636efa);
                color: white;
                border: none;
                border-radius: 10px;
                padding: 0.5rem 1rem;
                font-weight: 600;
                transition: all 0.3s ease;
            }
            .stButton > button:hover {
                transform: translateY(-2px);
                box-shadow: 0 5px 20px rgba(0, 204, 150, 0.3);
            }
            
            /* Expander styling */
            .streamlit-expanderHeader {
                background: rgba(30, 30, 30, 0.6);
                border-radius: 10px;
                border: 1px solid rgba(255, 255, 255, 0.1);
            }
            .streamlit-expanderHeader:hover {
                background: rgba(30, 30, 30, 0.8);
                border-color: rgba(0, 204, 150, 0.3);
            }
        </style>
        """, unsafe_allow_html=True)
        
        # Initialize and run enterprise application
        app = QuantEdgeProEnterprise()
        app.run_enterprise()
        
    except Exception as e:
        # Critical error handling
        st.error(f"""
        ##  Critical Application Error
        
        The enterprise application failed to start.
        
        **Error:** {str(e)}
        
        **Troubleshooting Steps:**
        1. Ensure all required Python packages are installed
        2. Check Python version (3.8+ required)
        3. Verify sufficient system resources
        4. Check internet connection for data fetching
        
        **Contact Enterprise Support:**
        - Email: enterprise-support@quantedge.com
        - Phone: +1-800-QUANT-EDGE
        - Reference Error: CRIT_{hashlib.md5(str(e).encode()).hexdigest()[:8]}
        """)
        
        # Display full traceback for debugging
        with st.expander(" Full Error Details", expanded=False):
            st.code(traceback.format_exc())

# ============================================================================
# 8. MAIN EXECUTION GUARD
# ============================================================================

if __name__ == "__main__":
    # Check if we should run enterprise or enhanced version
    # For now, always run enterprise
    enterprise_main()
